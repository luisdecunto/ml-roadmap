# Module 6: Feedforward Networks

**Focus:** Neural networks from scratch with backpropagation

## ðŸŽ¯ Coding Tasks

### Task 1: Single Neuron
- [ ] Implement forward pass
- [ ] Implement backward pass
- [ ] Test with numerical gradients

**Files to create:**
- `neuron.py`

---

### Task 2: Activation Functions
- [ ] ReLU (forward + backward)
- [ ] Sigmoid (forward + backward)
- [ ] Tanh (forward + backward)
- [ ] Softmax (forward + backward)

**Files to create:**
- `activations.py`

---

### Task 3: Two-Layer Network
- [ ] Forward pass with matrix operations
- [ ] Backward pass with chain rule
- [ ] Gradient checking

**Files to create:**
- `neural_network.py`

---

### Task 4: Training Loop
- [ ] Implement SGD training
- [ ] Loss computation
- [ ] Accuracy tracking
- [ ] Mini-batch handling

**Files to create:**
- `training.py`

---

### Project: MNIST Classifier (>95% accuracy)
- [ ] Build 2-layer network
- [ ] Train on MNIST
- [ ] Achieve >95% accuracy
- [ ] Plot loss and accuracy curves
- [ ] Analyze mistakes

**Files to create:**
- `mnist_classifier.ipynb`

---

## âœ… Success Criteria

- Neural network works correctly
- Gradient checking passes
- MNIST >95% accuracy achieved
- Understand backpropagation deeply

## ðŸ“š Resources

- [Neural Networks Guide](../guides/neural_networks_guide.html)
- [Neural Networks Exercises](../guides/exercises/neural_networks_exercises.html)
- [Solutions](../guides/solutions/neural_networks_solutions.html)

---

**Time estimate:** 12-16 hours
