<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 3 Mini-Project: Optimization Landscape Explorer - ML Roadmap</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        .markdown-body {
            line-height: 1.6;
        }
        .markdown-body h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            color: #1f2937;
            border-bottom: 3px solid #f59e0b;
            padding-bottom: 0.5rem;
        }
        .markdown-body h2 {
            font-size: 1.875rem;
            font-weight: 700;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: #374151;
        }
        .markdown-body h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            color: #4b5563;
        }
        .markdown-body p {
            margin-bottom: 1rem;
            color: #374151;
        }
        .markdown-body ul, .markdown-body ol {
            margin-bottom: 1rem;
            margin-left: 1.5rem;
        }
        .markdown-body li {
            margin-bottom: 0.5rem;
            color: #374151;
        }
        .markdown-body code {
            background-color: #f3f4f6;
            padding: 0.125rem 0.375rem;
            border-radius: 0.25rem;
            font-family: 'Courier New', monospace;
            font-size: 0.875rem;
            color: #dc2626;
        }
        .markdown-body pre {
            background-color: #1f2937;
            color: #f3f4f6;
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin-bottom: 1rem;
        }
        .markdown-body pre code {
            background-color: transparent;
            padding: 0;
            color: #f3f4f6;
        }
        .markdown-body a {
            color: #2563eb;
            text-decoration: underline;
        }
        .markdown-body a:hover {
            color: #1d4ed8;
        }
        .markdown-body hr {
            margin: 2rem 0;
            border: 0;
            border-top: 2px solid #e5e7eb;
        }
        .markdown-body blockquote {
            border-left: 4px solid #f59e0b;
            padding-left: 1rem;
            color: #6b7280;
            font-style: italic;
            margin: 1rem 0;
        }
        .markdown-body details {
            background-color: #fef3c7;
            border: 2px solid #fbbf24;
            border-radius: 0.5rem;
            padding: 1rem;
            margin: 1rem 0;
        }
        .markdown-body details[open] {
            background-color: #fef9e7;
        }
        .markdown-body summary {
            font-weight: 600;
            cursor: pointer;
            color: #d97706;
            user-select: none;
            padding: 0.5rem;
            margin: -1rem;
            margin-bottom: 1rem;
            background-color: #fde68a;
            border-radius: 0.375rem;
        }
        .markdown-body summary:hover {
            background-color: #fcd34d;
            color: #b45309;
        }
        .research-box {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            border-left: 4px solid #f59e0b;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.5rem;
        }
        .milestone-box {
            background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%);
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.5rem;
        }
    </style>
</head>
<body class="bg-gradient-to-br from-amber-50 via-orange-50 to-yellow-50 min-h-screen">
    <div class="max-w-4xl mx-auto p-4 md:p-8">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <div class="flex items-center justify-between mb-4">
                <h1 class="text-2xl font-bold text-gray-800">üì¶ Mini-Project: Optimization Landscape Explorer</h1>
                <a href="../index.html" class="px-4 py-2 bg-amber-600 hover:bg-amber-700 text-white rounded-lg text-sm font-semibold">
                    ‚Üê Back to Roadmap
                </a>
            </div>
            <p class="text-gray-600">
                <strong>Module 3:</strong> Optimization & Gradient Descent | <strong>Estimated Time:</strong> 25-35 hours
            </p>
        </div>

        <!-- Content Container -->
        <div class="bg-white rounded-lg shadow-lg p-6 md:p-8 markdown-body">
            <div id="guide-content"></div>
        </div>
    </div>

    <script>
        const markdown = `# Optimization Landscape Explorer

## üéØ Project Overview

**Challenge:** Build an interactive tool to visualize and understand optimization landscapes, comparing different gradient descent variants and analyzing their behavior on various loss surfaces.

**Why This Matters:** This project forces you to deeply understand:
- How different optimizers navigate loss landscapes
- Why momentum helps escape local minima
- When adaptive learning rates (Adam, RMSprop) outperform vanilla SGD
- The role of learning rate scheduling
- How saddle points and plateaus affect convergence

You are **NOT** just implementing formulas. You are building a **research tool** to develop intuition about optimization dynamics.

---

## üìö Additional Resources

Before starting, familiarize yourself with these resources:

- [Sebastian Ruder: Overview of Gradient Descent Algorithms](https://arxiv.org/abs/1609.04747)
- [CS231n: Optimization](http://cs231n.github.io/optimization-1/)
- [Distill: Why Momentum Really Works](https://distill.pub/2017/momentum/)
- [Adam Paper](https://arxiv.org/abs/1412.6980)

---

## üìö Learning Objectives

By completing this project, you will be able to:

1. **Implement** all major optimizers from scratch (SGD, Momentum, RMSprop, Adam)
2. **Visualize** optimization trajectories on 2D/3D loss surfaces
3. **Analyze** convergence behavior and failure modes
4. **Design** custom learning rate schedules
5. **Compare** optimizer performance quantitatively
6. **Explain** when to use which optimizer and why
7. **Debug** optimization issues in practice

---

## üî¨ Problem Statement

### Core Challenge

Design and implement an optimization landscape explorer that:

1. **Creates diverse test functions:** Convex, non-convex, with saddle points, plateaus
2. **Implements optimizers:** Vanilla SGD, Momentum, Nesterov, RMSprop, Adam, AdamW
3. **Visualizes trajectories:** 2D contour plots, 3D surface plots, convergence curves
4. **Compares performance:** Side-by-side comparisons with metrics
5. **Provides insights:** Explains why each optimizer behaves the way it does

### Technical Constraints

- Must implement optimizers from scratch (no PyTorch/TensorFlow optimizers)
- Must support batched gradient computation
- Must visualize at least 5 different test functions
- Must track and plot: loss curve, gradient norms, parameter updates
- Must run interactive comparisons (adjustable hyperparameters)

---

## ü§î Research Questions

These questions should guide your design. **Answer them through experiments:**

### Fundamental Questions

1. **Why does momentum help?**
   - How does it affect oscillations in narrow valleys?
   - When does high momentum cause overshooting?
   - What's the difference between classical and Nesterov momentum?

2. **What do adaptive learning rates solve?**
   - Why does RMSprop work better on non-stationary problems?
   - How does Adam combine momentum and adaptive rates?
   - When should you use AdamW instead of Adam?

3. **How do learning rates affect convergence?**
   - Too large: What happens? (divergence, oscillation?)
   - Too small: What happens? (slow convergence?)
   - Can you design a schedule that starts large and decreases?

4. **What are saddle points and why do they matter?**
   - How do they slow down convergence?
   - Which optimizers escape saddle points faster?
   - Can you create a test function with a prominent saddle point?

<details>
<summary>üí° Stuck? Click for hints on these fundamentals</summary>

### Understanding Momentum

**What it does:**
\`\`\`python
# Vanilla SGD
theta = theta - learning_rate * gradient

# SGD with Momentum
velocity = beta * velocity + gradient
theta = theta - learning_rate * velocity
\`\`\`

**Why it helps:**
- Accumulates gradients over time ‚Üí smooths out oscillations
- Builds up speed in consistent directions
- Dampens oscillations in perpendicular directions

**Experiment to try:**
\`\`\`python
# Create a narrow valley function
def rosenbrock(x, y, a=1, b=100):
    return (a - x)**2 + b * (y - x**2)**2

# Compare vanilla SGD vs momentum on this
# Vanilla: oscillates in narrow valley
# Momentum: moves smoothly along valley floor
\`\`\`

---

### Adaptive Learning Rates

**RMSprop:**
\`\`\`python
# Maintains running average of squared gradients
squared_grad_avg = beta * squared_grad_avg + (1 - beta) * gradient**2
theta = theta - learning_rate * gradient / (sqrt(squared_grad_avg) + epsilon)
\`\`\`

**Why:** Adapts learning rate per-parameter. Parameters with consistently large gradients get smaller effective learning rates.

**Adam (combines momentum + RMSprop):**
\`\`\`python
# First moment (momentum)
m = beta1 * m + (1 - beta1) * gradient

# Second moment (RMSprop)
v = beta2 * v + (1 - beta2) * gradient**2

# Bias correction
m_hat = m / (1 - beta1**t)
v_hat = v / (1 - beta2**t)

# Update
theta = theta - learning_rate * m_hat / (sqrt(v_hat) + epsilon)
\`\`\`

**When to use:**
- Adam: Default choice for deep learning (works well out-of-the-box)
- AdamW: When you need weight decay (better generalization)
- RMSprop: For RNNs or when gradients are very noisy
- Momentum: When you understand the landscape and can tune beta

---

### Learning Rate Schedules

**Common schedules:**

1. **Step Decay:**
\`\`\`python
lr = initial_lr * decay_rate ** (epoch // step_size)
\`\`\`

2. **Exponential Decay:**
\`\`\`python
lr = initial_lr * exp(-decay_rate * epoch)
\`\`\`

3. **Cosine Annealing:**
\`\`\`python
lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + cos(pi * epoch / total_epochs))
\`\`\`

4. **1Cycle:**
\`\`\`python
# Increase lr first half, decrease second half
# Used by fast.ai
\`\`\`

**Your task:** Implement at least 2 schedules and compare their effect on convergence speed.

---

### Saddle Points

**What they are:**
- Points where gradient = 0 but NOT a minimum
- Slope is flat in some directions, curved in others
- Example: f(x,y) = x¬≤ - y¬≤  (saddle at origin)

**Why they matter:**
- Gradients become very small near saddle points
- Can slow down or stall optimization
- More common in high dimensions

**Test function:**
\`\`\`python
def saddle_function(x, y):
    return x**2 - y**2

# At (0,0): gradient = 0, but it's a saddle point
# x-direction: curves up (minimum)
# y-direction: curves down (maximum)
\`\`\`

**Experiment:** Which optimizer escapes this saddle point fastest?

</details>

### Advanced Questions

5. **How does batch size affect optimization?**
   - Full batch vs mini-batch vs stochastic
   - Noise in gradients: helpful or harmful?

6. **Can you design a function where SGD fails but Adam succeeds?**
   - What properties make it hard for SGD?

7. **What happens with very high-dimensional loss landscapes?**
   - Can you extend your visualizations beyond 2D?

---

## üìã Requirements & Specifications

### Phase 1: Test Functions & Visualization (Required)

**Functionality:**
- Implement at least 5 test functions with different properties
- Create 2D contour plots with customizable resolution
- Create 3D surface plots for visual understanding
- Support gradient computation (analytical or numerical)

**Test Functions to include:**
1. **Convex:** Quadratic bowl
2. **Non-convex:** Rosenbrock (narrow valley)
3. **Saddle point:** x¬≤ - y¬≤
4. **Many local minima:** Ackley or Rastrigin
5. **Plateau:** Beale function

<details>
<summary>üí° Stuck? Click for test function implementations</summary>

### Test Function Library

\`\`\`python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class TestFunctions:
    """Collection of optimization test functions."""

    @staticmethod
    def sphere(x):
        """
        Simple convex quadratic function.
        Global minimum at origin: f(0,0) = 0
        """
        return np.sum(x**2, axis=-1)

    @staticmethod
    def sphere_grad(x):
        """Gradient of sphere function."""
        return 2 * x

    @staticmethod
    def rosenbrock(x, a=1, b=100):
        """
        Rosenbrock function (banana valley).
        Global minimum at (a, a¬≤): f(a,a¬≤) = 0
        Very narrow valley - hard to optimize!
        """
        if len(x.shape) == 1:
            return (a - x[0])**2 + b * (x[1] - x[0]**2)**2
        return (a - x[..., 0])**2 + b * (x[..., 1] - x[..., 0]**2)**2

    @staticmethod
    def rosenbrock_grad(x, a=1, b=100):
        """Gradient of Rosenbrock function."""
        grad = np.zeros_like(x)
        grad[0] = -2 * (a - x[0]) - 4 * b * x[0] * (x[1] - x[0]**2)
        grad[1] = 2 * b * (x[1] - x[0]**2)
        return grad

    @staticmethod
    def saddle(x):
        """
        Simple saddle point function.
        Saddle at origin: f(0,0) = 0
        Minimum along x-axis, maximum along y-axis
        """
        if len(x.shape) == 1:
            return x[0]**2 - x[1]**2
        return x[..., 0]**2 - x[..., 1]**2

    @staticmethod
    def saddle_grad(x):
        """Gradient of saddle function."""
        grad = np.zeros_like(x)
        grad[0] = 2 * x[0]
        grad[1] = -2 * x[1]
        return grad

    @staticmethod
    def beale(x):
        """
        Beale function (has plateaus).
        Global minimum at (3, 0.5): f(3, 0.5) = 0
        """
        if len(x.shape) == 1:
            x1, x2 = x[0], x[1]
        else:
            x1, x2 = x[..., 0], x[..., 1]

        term1 = (1.5 - x1 + x1*x2)**2
        term2 = (2.25 - x1 + x1*x2**2)**2
        term3 = (2.625 - x1 + x1*x2**3)**2
        return term1 + term2 + term3

    @staticmethod
    def beale_grad(x):
        """Gradient of Beale function (numerical approximation)."""
        eps = 1e-8
        grad = np.zeros_like(x)
        for i in range(len(x)):
            x_plus = x.copy()
            x_plus[i] += eps
            x_minus = x.copy()
            x_minus[i] -= eps
            grad[i] = (TestFunctions.beale(x_plus) - TestFunctions.beale(x_minus)) / (2 * eps)
        return grad

    @staticmethod
    def ackley(x, a=20, b=0.2, c=2*np.pi):
        """
        Ackley function (many local minima).
        Global minimum at origin: f(0,0) = 0
        """
        if len(x.shape) == 1:
            d = len(x)
            sum_sq = np.sum(x**2)
            sum_cos = np.sum(np.cos(c * x))
        else:
            d = x.shape[-1]
            sum_sq = np.sum(x**2, axis=-1)
            sum_cos = np.sum(np.cos(c * x), axis=-1)

        term1 = -a * np.exp(-b * np.sqrt(sum_sq / d))
        term2 = -np.exp(sum_cos / d)
        return term1 + term2 + a + np.e

    @staticmethod
    def ackley_grad(x, a=20, b=0.2, c=2*np.pi):
        """Gradient of Ackley function."""
        d = len(x)
        sum_sq = np.sum(x**2)
        sqrt_term = np.sqrt(sum_sq / d)

        grad_term1 = a * b * np.exp(-b * sqrt_term) * x / (d * sqrt_term)
        grad_term2 = c * np.exp(np.sum(np.cos(c * x)) / d) * np.sin(c * x) / d

        return grad_term1 + grad_term2

def visualize_function(func, x_range=(-5, 5), y_range=(-5, 5), resolution=100):
    """
    Visualize a 2D function with contour and 3D surface plots.

    Args:
        func: Function to visualize (takes array [x, y])
        x_range, y_range: (min, max) for each axis
        resolution: Grid resolution
    """
    # Create mesh grid
    x = np.linspace(x_range[0], x_range[1], resolution)
    y = np.linspace(y_range[0], y_range[1], resolution)
    X, Y = np.meshgrid(x, y)

    # Evaluate function
    points = np.stack([X, Y], axis=-1)
    Z = func(points)

    # Create figure with subplots
    fig = plt.figure(figsize=(15, 5))

    # Contour plot
    ax1 = fig.add_subplot(131)
    contour = ax1.contour(X, Y, Z, levels=20, cmap='viridis')
    ax1.clabel(contour, inline=True, fontsize=8)
    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title('Contour Plot')
    ax1.grid(True, alpha=0.3)

    # Filled contour plot
    ax2 = fig.add_subplot(132)
    ax2.contourf(X, Y, Z, levels=20, cmap='viridis')
    ax2.set_xlabel('x')
    ax2.set_ylabel('y')
    ax2.set_title('Filled Contour Plot')

    # 3D surface plot
    ax3 = fig.add_subplot(133, projection='3d')
    surf = ax3.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)
    ax3.set_xlabel('x')
    ax3.set_ylabel('y')
    ax3.set_zlabel('f(x,y)')
    ax3.set_title('3D Surface Plot')
    fig.colorbar(surf, ax=ax3, shrink=0.5)

    plt.tight_layout()
    return fig

# Example usage
funcs = TestFunctions()
fig = visualize_function(funcs.rosenbrock, x_range=(-2, 2), y_range=(-1, 3))
plt.savefig('rosenbrock_visualization.png', dpi=150)
plt.show()
\`\`\`

**Why each function:**
- **Sphere:** Baseline - simplest case
- **Rosenbrock:** Tests handling of narrow valleys
- **Saddle:** Tests saddle point escape
- **Beale:** Tests plateau navigation
- **Ackley:** Tests local minima avoidance

</details>

### Phase 2: Optimizer Implementations (Required)

**Deliverables:**
Implement from scratch:
1. Vanilla SGD
2. SGD with Momentum
3. SGD with Nesterov Momentum
4. RMSprop
5. Adam
6. (Optional) AdamW

Each must:
- Support batched gradients
- Track parameter history for visualization
- Support learning rate schedules
- Handle numerical stability (e.g., epsilon in denominators)

<details>
<summary>üí° Stuck? Click for optimizer implementations</summary>

### Complete Optimizer Library

\`\`\`python
class Optimizer:
    """Base class for optimizers."""

    def __init__(self, learning_rate=0.01):
        self.learning_rate = learning_rate
        self.history = {'params': [], 'loss': [], 'grad_norm': []}

    def step(self, params, grads):
        """Perform one optimization step. Override in subclasses."""
        raise NotImplementedError

    def zero_history(self):
        """Clear optimization history."""
        self.history = {'params': [], 'loss': [], 'grad_norm': []}

class SGD(Optimizer):
    """Vanilla Stochastic Gradient Descent."""

    def step(self, params, grads):
        """
        params: current parameters (numpy array)
        grads: gradients at current parameters
        """
        # Store for visualization
        self.history['params'].append(params.copy())
        self.history['grad_norm'].append(np.linalg.norm(grads))

        # Update: theta = theta - lr * gradient
        params_new = params - self.learning_rate * grads

        return params_new

class MomentumSGD(Optimizer):
    """SGD with classical momentum."""

    def __init__(self, learning_rate=0.01, beta=0.9):
        super().__init__(learning_rate)
        self.beta = beta
        self.velocity = None

    def step(self, params, grads):
        # Initialize velocity on first step
        if self.velocity is None:
            self.velocity = np.zeros_like(params)

        # Store for visualization
        self.history['params'].append(params.copy())
        self.history['grad_norm'].append(np.linalg.norm(grads))

        # Update velocity: v = beta * v + gradient
        self.velocity = self.beta * self.velocity + grads

        # Update parameters: theta = theta - lr * v
        params_new = params - self.learning_rate * self.velocity

        return params_new

class NesterovMomentum(Optimizer):
    """SGD with Nesterov accelerated gradient."""

    def __init__(self, learning_rate=0.01, beta=0.9):
        super().__init__(learning_rate)
        self.beta = beta
        self.velocity = None

    def step(self, params, grads):
        # Initialize velocity on first step
        if self.velocity is None:
            self.velocity = np.zeros_like(params)

        # Store for visualization
        self.history['params'].append(params.copy())
        self.history['grad_norm'].append(np.linalg.norm(grads))

        # Nesterov update
        velocity_prev = self.velocity.copy()
        self.velocity = self.beta * self.velocity + grads

        # Look-ahead step
        params_new = params - self.learning_rate * (
            self.beta * self.velocity + grads
        )

        return params_new

class RMSprop(Optimizer):
    """RMSprop optimizer with adaptive learning rates."""

    def __init__(self, learning_rate=0.01, beta=0.9, epsilon=1e-8):
        super().__init__(learning_rate)
        self.beta = beta
        self.epsilon = epsilon
        self.squared_grad_avg = None

    def step(self, params, grads):
        # Initialize on first step
        if self.squared_grad_avg is None:
            self.squared_grad_avg = np.zeros_like(params)

        # Store for visualization
        self.history['params'].append(params.copy())
        self.history['grad_norm'].append(np.linalg.norm(grads))

        # Update running average of squared gradients
        self.squared_grad_avg = (
            self.beta * self.squared_grad_avg +
            (1 - self.beta) * grads**2
        )

        # Adaptive update
        params_new = params - self.learning_rate * grads / (
            np.sqrt(self.squared_grad_avg) + self.epsilon
        )

        return params_new

class Adam(Optimizer):
    """Adam optimizer (combines momentum + RMSprop)."""

    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):
        super().__init__(learning_rate)
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.m = None  # First moment
        self.v = None  # Second moment
        self.t = 0     # Time step

    def step(self, params, grads):
        # Initialize on first step
        if self.m is None:
            self.m = np.zeros_like(params)
            self.v = np.zeros_like(params)

        self.t += 1

        # Store for visualization
        self.history['params'].append(params.copy())
        self.history['grad_norm'].append(np.linalg.norm(grads))

        # Update biased first moment estimate
        self.m = self.beta1 * self.m + (1 - self.beta1) * grads

        # Update biased second moment estimate
        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2

        # Bias correction
        m_hat = self.m / (1 - self.beta1**self.t)
        v_hat = self.v / (1 - self.beta2**self.t)

        # Update parameters
        params_new = params - self.learning_rate * m_hat / (
            np.sqrt(v_hat) + self.epsilon
        )

        return params_new

class AdamW(Adam):
    """AdamW: Adam with decoupled weight decay."""

    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,
                 epsilon=1e-8, weight_decay=0.01):
        super().__init__(learning_rate, beta1, beta2, epsilon)
        self.weight_decay = weight_decay

    def step(self, params, grads):
        # Get Adam update
        params_new = super().step(params, grads)

        # Add weight decay (applied to parameters, not gradients)
        params_new = params_new - self.learning_rate * self.weight_decay * params

        return params_new
\`\`\`

**Why each piece:**
- **History tracking:** Enables trajectory visualization
- **Lazy initialization:** Handles any parameter dimension
- **Epsilon:** Prevents division by zero
- **Bias correction (Adam):** Corrects for initialization bias
- **Weight decay (AdamW):** Improves generalization

</details>

### Phase 3: Comparative Analysis (Required)

**Challenge:** Compare all optimizers on all test functions.

**Metrics to track:**
- Final loss value
- Number of iterations to convergence
- Total distance traveled
- Gradient norm over time
- Parameter trajectory visualization

**Deliverable:**
- Side-by-side trajectory plots
- Convergence curves for all optimizers
- Statistical summary table
- Analysis of which optimizer wins on which function type

<details>
<summary>üí° Stuck? Click for comparison framework</summary>

### Optimizer Comparison Framework

\`\`\`python
def compare_optimizers(func, func_grad, initial_point, optimizers_dict,
                      n_iterations=100, tolerance=1e-6):
    """
    Compare multiple optimizers on a single function.

    Args:
        func: Objective function
        func_grad: Gradient function
        initial_point: Starting point for optimization
        optimizers_dict: Dict of {name: optimizer_instance}
        n_iterations: Max iterations
        tolerance: Convergence tolerance

    Returns:
        results: Dict with optimization results for each optimizer
    """
    results = {}

    for name, optimizer in optimizers_dict.items():
        optimizer.zero_history()
        params = initial_point.copy()

        for i in range(n_iterations):
            # Compute gradient
            grads = func_grad(params)

            # Store loss
            loss = func(params)
            optimizer.history['loss'].append(loss)

            # Check convergence
            if np.linalg.norm(grads) < tolerance:
                print(f"{name} converged at iteration {i}")
                break

            # Optimization step
            params = optimizer.step(params, grads)

        # Store final results
        results[name] = {
            'final_params': params,
            'final_loss': func(params),
            'iterations': i + 1,
            'history': optimizer.history
        }

    return results

def visualize_comparison(func, results, x_range=(-5, 5), y_range=(-5, 5)):
    """Visualize optimization trajectories for multiple optimizers."""
    # Create mesh for contour plot
    x = np.linspace(x_range[0], x_range[1], 100)
    y = np.linspace(y_range[0], y_range[1], 100)
    X, Y = np.meshgrid(x, y)
    points = np.stack([X, Y], axis=-1)
    Z = func(points)

    fig = plt.figure(figsize=(18, 6))

    # Plot 1: All trajectories on contour
    ax1 = fig.add_subplot(131)
    ax1.contour(X, Y, Z, levels=20, cmap='gray', alpha=0.3)

    colors = plt.cm.tab10(np.linspace(0, 1, len(results)))

    for (name, result), color in zip(results.items(), colors):
        trajectory = np.array(result['history']['params'])
        ax1.plot(trajectory[:, 0], trajectory[:, 1],
                'o-', label=name, color=color, markersize=3, linewidth=1.5)
        # Mark start and end
        ax1.plot(trajectory[0, 0], trajectory[0, 1],
                'o', color=color, markersize=10, markeredgecolor='black')
        ax1.plot(trajectory[-1, 0], trajectory[-1, 1],
                '*', color=color, markersize=15, markeredgecolor='black')

    ax1.set_xlabel('x')
    ax1.set_ylabel('y')
    ax1.set_title('Optimization Trajectories')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: Loss curves
    ax2 = fig.add_subplot(132)
    for (name, result), color in zip(results.items(), colors):
        loss_history = result['history']['loss']
        ax2.semilogy(loss_history, label=name, color=color, linewidth=2)

    ax2.set_xlabel('Iteration')
    ax2.set_ylabel('Loss (log scale)')
    ax2.set_title('Convergence Curves')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: Gradient norms
    ax3 = fig.add_subplot(133)
    for (name, result), color in zip(results.items(), colors):
        grad_norms = result['history']['grad_norm']
        ax3.semilogy(grad_norms, label=name, color=color, linewidth=2)

    ax3.set_xlabel('Iteration')
    ax3.set_ylabel('Gradient Norm (log scale)')
    ax3.set_title('Gradient Evolution')
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    plt.tight_layout()
    return fig

def print_summary_table(results):
    """Print comparison table."""
    print("\\n" + "="*80)
    print(f"{'Optimizer':<20} {'Final Loss':<15} {'Iterations':<12} {'Final Params'}")
    print("="*80)

    for name, result in results.items():
        print(f"{name:<20} {result['final_loss']:<15.6e} {result['iterations']:<12} "
              f"{result['final_params']}")
    print("="*80)

# Example usage
funcs = TestFunctions()

# Setup optimizers
optimizers = {
    'SGD': SGD(learning_rate=0.01),
    'Momentum': MomentumSGD(learning_rate=0.01, beta=0.9),
    'Nesterov': NesterovMomentum(learning_rate=0.01, beta=0.9),
    'RMSprop': RMSprop(learning_rate=0.01),
    'Adam': Adam(learning_rate=0.1)
}

# Compare on Rosenbrock
initial = np.array([-1.5, 2.0])
results = compare_optimizers(
    funcs.rosenbrock,
    funcs.rosenbrock_grad,
    initial,
    optimizers,
    n_iterations=500
)

# Visualize
fig = visualize_comparison(funcs.rosenbrock, results, x_range=(-2, 2), y_range=(-1, 3))
plt.savefig('optimizer_comparison_rosenbrock.png', dpi=150)

# Print summary
print_summary_table(results)
\`\`\`

**What to observe:**
- Which optimizer finds the minimum fastest?
- Which optimizer takes the smoothest path?
- Do any optimizers get stuck or overshoot?
- How do convergence speeds compare?

</details>

### Phase 4: Learning Rate Schedules (Optional)

**Challenge:** Implement and compare learning rate schedules.

**Schedules to try:**
1. Step decay
2. Exponential decay
3. Cosine annealing
4. Warm-up + decay

**Experiment:** Does a good schedule help SGD beat Adam?

<details>
<summary><strong>üí° Implementation Guide: Learning Rate Schedules</strong></summary>

Learning rate schedules can significantly improve optimization, especially for vanilla SGD and momentum-based methods.

#### 1. Step Decay

Reduce learning rate by a factor at fixed intervals:

\`\`\`python
class StepDecaySchedule:
    """
    Reduce learning rate by factor every 'step_size' iterations.
    """
    def __init__(self, initial_lr, decay_factor=0.5, step_size=100):
        self.initial_lr = initial_lr
        self.decay_factor = decay_factor
        self.step_size = step_size

    def get_lr(self, iteration):
        """Get learning rate at given iteration."""
        return self.initial_lr * (self.decay_factor ** (iteration // self.step_size))

# Usage example
schedule = StepDecaySchedule(initial_lr=0.1, decay_factor=0.5, step_size=100)

# In optimization loop:
for i in range(n_iterations):
    lr = schedule.get_lr(i)
    optimizer.learning_rate = lr
    # ... rest of optimization
\`\`\`

**When to use:** Good for well-understood problems where you know approximately when to reduce learning rate.

#### 2. Exponential Decay

Smoothly decay learning rate over time:

\`\`\`python
class ExponentialDecaySchedule:
    """
    Exponentially decay learning rate: lr = initial_lr * (decay_rate^iteration)
    """
    def __init__(self, initial_lr, decay_rate=0.99):
        self.initial_lr = initial_lr
        self.decay_rate = decay_rate

    def get_lr(self, iteration):
        return self.initial_lr * (self.decay_rate ** iteration)

# Usage
schedule = ExponentialDecaySchedule(initial_lr=0.1, decay_rate=0.995)

for i in range(n_iterations):
    lr = schedule.get_lr(i)
    optimizer.learning_rate = lr
\`\`\`

**Trade-off:** Smooth decay, but requires careful tuning of decay_rate.

#### 3. Cosine Annealing

Decay learning rate following a cosine curve:

\`\`\`python
import numpy as np

class CosineAnnealingSchedule:
    """
    Cosine annealing: lr varies between max_lr and min_lr following cosine curve.
    Popular in deep learning (used in training ResNets, transformers, etc.)
    """
    def __init__(self, initial_lr, min_lr=0.0, T_max=500):
        self.initial_lr = initial_lr
        self.min_lr = min_lr
        self.T_max = T_max  # Period of cosine cycle

    def get_lr(self, iteration):
        """Cosine annealing formula."""
        return self.min_lr + 0.5 * (self.initial_lr - self.min_lr) * \
               (1 + np.cos(np.pi * iteration / self.T_max))

# Usage
schedule = CosineAnnealingSchedule(initial_lr=0.1, min_lr=0.001, T_max=500)

for i in range(n_iterations):
    lr = schedule.get_lr(i)
    optimizer.learning_rate = lr
\`\`\`

**Benefit:** Smooth decay with natural minimum, works well in practice without much tuning.

#### 4. Warmup + Decay

Linear warmup followed by decay (common in transformer training):

\`\`\`python
class WarmupCosineSchedule:
    """
    Linear warmup for 'warmup_iterations', then cosine decay.
    This is the schedule used in many modern transformers.
    """
    def __init__(self, initial_lr, warmup_iterations=50, max_iterations=500, min_lr=0.0):
        self.initial_lr = initial_lr
        self.warmup_iterations = warmup_iterations
        self.max_iterations = max_iterations
        self.min_lr = min_lr

    def get_lr(self, iteration):
        if iteration < self.warmup_iterations:
            # Linear warmup
            return self.initial_lr * (iteration / self.warmup_iterations)
        else:
            # Cosine decay
            progress = (iteration - self.warmup_iterations) / \
                      (self.max_iterations - self.warmup_iterations)
            return self.min_lr + 0.5 * (self.initial_lr - self.min_lr) * \
                   (1 + np.cos(np.pi * progress))

# Usage
schedule = WarmupCosineSchedule(initial_lr=0.1, warmup_iterations=50,
                                max_iterations=500, min_lr=0.001)

for i in range(n_iterations):
    lr = schedule.get_lr(i)
    optimizer.learning_rate = lr
\`\`\`

**Why warmup?** Prevents instability at the start when gradients can be large and optimizer statistics haven't stabilized.

#### Complete Example: Comparing Schedules

\`\`\`python
def run_optimizer_with_schedule(func, grad_func, initial, optimizer, schedule, n_iterations=500):
    """
    Run optimizer with a learning rate schedule.
    """
    params = initial.copy()
    trajectory = [params.copy()]
    losses = [func(params)]
    learning_rates = []

    optimizer.reset()

    for i in range(n_iterations):
        # Update learning rate according to schedule
        lr = schedule.get_lr(i)
        optimizer.learning_rate = lr
        learning_rates.append(lr)

        # Optimization step
        grads = grad_func(params)
        params = optimizer.step(params, grads)

        trajectory.append(params.copy())
        losses.append(func(params))

    return {
        'trajectory': np.array(trajectory),
        'losses': np.array(losses),
        'learning_rates': np.array(learning_rates),
        'final_params': params,
        'final_loss': losses[-1]
    }

# Compare different schedules on SGD
schedules = {
    'Constant': None,  # No schedule
    'StepDecay': StepDecaySchedule(initial_lr=0.01, decay_factor=0.5, step_size=100),
    'Exponential': ExponentialDecaySchedule(initial_lr=0.01, decay_rate=0.995),
    'Cosine': CosineAnnealingSchedule(initial_lr=0.01, min_lr=0.0001, T_max=500),
    'WarmupCosine': WarmupCosineSchedule(initial_lr=0.01, warmup_iterations=50,
                                          max_iterations=500, min_lr=0.0001)
}

funcs = TestFunctions()
results_with_schedule = {}

for name, schedule in schedules.items():
    print(f"Testing {name}...")
    if schedule is None:
        # Constant learning rate
        optimizer = SGD(learning_rate=0.01)
        result = run_optimizer(funcs.rosenbrock, funcs.rosenbrock_grad,
                              np.array([-1.5, 2.5]), optimizer, n_iterations=500)
    else:
        # With schedule
        optimizer = SGD(learning_rate=0.01)  # Initial LR (will be updated by schedule)
        result = run_optimizer_with_schedule(funcs.rosenbrock, funcs.rosenbrock_grad,
                                             np.array([-1.5, 2.5]), optimizer,
                                             schedule, n_iterations=500)

    results_with_schedule[name] = result

# Visualize comparison
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Plot 1: Trajectories
ax1 = axes[0]
x = np.linspace(-2, 2, 100)
y = np.linspace(-1, 3, 100)
X, Y = np.meshgrid(x, y)
Z = np.array([[funcs.rosenbrock(np.array([xi, yi])) for xi in x] for yi in y])
ax1.contour(X, Y, Z, levels=30, cmap='gray', alpha=0.3)

for name, result in results_with_schedule.items():
    traj = result['trajectory']
    ax1.plot(traj[:, 0], traj[:, 1], 'o-', label=name, markersize=2, linewidth=1.5)

ax1.set_xlabel('x‚ÇÄ')
ax1.set_ylabel('x‚ÇÅ')
ax1.set_title('Trajectories with Different Schedules')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Loss curves
ax2 = axes[1]
for name, result in results_with_schedule.items():
    ax2.semilogy(result['losses'], label=name, linewidth=2)

ax2.set_xlabel('Iteration')
ax2.set_ylabel('Loss (log scale)')
ax2.set_title('Convergence Comparison')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Learning rate schedules
ax3 = axes[2]
for name, result in results_with_schedule.items():
    if 'learning_rates' in result:
        ax3.plot(result['learning_rates'], label=name, linewidth=2)

ax3.set_xlabel('Iteration')
ax3.set_ylabel('Learning Rate')
ax3.set_title('Learning Rate Schedules')
ax3.legend()
ax3.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('schedule_comparison.png', dpi=150)
plt.show()

# Print final results
print("\n" + "="*70)
print(f"{'Schedule':<20} {'Final Loss':<15} {'Iterations to <0.1':<20}")
print("="*70)

for name, result in results_with_schedule.items():
    final_loss = result['final_loss']
    # Find iteration where loss first drops below 0.1
    iterations_to_converge = np.argmax(result['losses'] < 0.1)
    if result['losses'][iterations_to_converge] >= 0.1:
        iterations_to_converge = "Did not converge"
    print(f"{name:<20} {final_loss:<15.6f} {str(iterations_to_converge):<20}")

print("="*70)
\`\`\`

#### Key Insights

**Does scheduling help SGD beat Adam?**

Test this yourself! Expected observations:
- **Constant LR SGD**: Slow convergence, may not reach minimum
- **Step Decay**: Significant improvement, but sensitive to step timing
- **Exponential Decay**: Smooth improvement, requires careful tuning
- **Cosine Annealing**: Often best performance, smooth and predictable
- **Warmup + Cosine**: Most robust, used in state-of-the-art training

**General findings:**
- Good schedule can make SGD competitive with Adam on well-behaved functions
- Adam still typically better on functions with very different curvatures
- Schedules help more on optimization problems with clear phases (exploration ‚Üí refinement)

**Practical tips:**
1. Start with cosine annealing - good default choice
2. Use warmup if optimization is unstable at start
3. For SGD, good schedule is often essential
4. For Adam, schedules provide smaller improvements but still helpful

</details>

---

<details>
<summary>üí° Click for Complete Reference Implementation (Try on your own first!)</summary>

# Complete Reference Implementation

Below is a full working implementation combining all phases into a comprehensive optimizer framework.

\`\`\`python
"""
Optimization Landscape Explorer - Complete Reference Implementation
Combines all phases into a unified framework for comparing optimizers.
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
from typing import Dict, List, Tuple, Callable

# ============================================================================
# Test Functions (Phase 1)
# ============================================================================

class TestFunctions:
    """Collection of optimization test functions."""

    @staticmethod
    def sphere(x):
        """Simple convex quadratic. Global minimum at (0, 0)."""
        return x[0]**2 + x[1]**2

    @staticmethod
    def sphere_grad(x):
        return np.array([2*x[0], 2*x[1]])

    @staticmethod
    def rosenbrock(x, a=1, b=100):
        """Rosenbrock's banana function. Narrow curved valley.
        Global minimum at (a, a¬≤)."""
        return (a - x[0])**2 + b*(x[1] - x[0]**2)**2

    @staticmethod
    def rosenbrock_grad(x, a=1, b=100):
        dx0 = -2*(a - x[0]) - 4*b*x[0]*(x[1] - x[0]**2)
        dx1 = 2*b*(x[1] - x[0]**2)
        return np.array([dx0, dx1])

    @staticmethod
    def ackley(x, a=20, b=0.2, c=2*np.pi):
        """Ackley function. Many local minima.
        Global minimum at (0, 0)."""
        term1 = -a * np.exp(-b * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))
        term2 = -np.exp(0.5 * (np.cos(c*x[0]) + np.cos(c*x[1])))
        return term1 + term2 + a + np.e

    @staticmethod
    def ackley_grad(x, a=20, b=0.2, c=2*np.pi):
        r = np.sqrt(x[0]**2 + x[1]**2)
        if r < 1e-10:
            return np.array([0.0, 0.0])

        exp1 = np.exp(-b * r)
        exp2 = np.exp(0.5 * (np.cos(c*x[0]) + np.cos(c*x[1])))

        dx0 = (a * b * x[0] / r) * exp1 + (0.5 * c * np.sin(c*x[0])) * exp2
        dx1 = (a * b * x[1] / r) * exp1 + (0.5 * c * np.sin(c*x[1])) * exp2

        return np.array([dx0, dx1])

    @staticmethod
    def saddle(x):
        """Saddle function. Saddle point at origin."""
        return x[0]**2 - x[1]**2

    @staticmethod
    def saddle_grad(x):
        return np.array([2*x[0], -2*x[1]])

    @staticmethod
    def beale(x):
        """Beale function. Has plateaus and valleys.
        Global minimum at (3, 0.5)."""
        term1 = (1.5 - x[0] + x[0]*x[1])**2
        term2 = (2.25 - x[0] + x[0]*x[1]**2)**2
        term3 = (2.625 - x[0] + x[0]*x[1]**3)**2
        return term1 + term2 + term3

    @staticmethod
    def beale_grad(x):
        t1 = 1.5 - x[0] + x[0]*x[1]
        t2 = 2.25 - x[0] + x[0]*x[1]**2
        t3 = 2.625 - x[0] + x[0]*x[1]**3

        dx0 = (2*t1*(-1 + x[1]) +
               2*t2*(-1 + x[1]**2) +
               2*t3*(-1 + x[1]**3))
        dx1 = (2*t1*(x[0]) +
               2*t2*(2*x[0]*x[1]) +
               2*t3*(3*x[0]*x[1]**2))

        return np.array([dx0, dx1])

# ============================================================================
# Optimizer Base Class and Implementations (Phase 2)
# ============================================================================

class Optimizer:
    """Base class for all optimizers."""

    def __init__(self, learning_rate=0.01):
        self.learning_rate = learning_rate
        self.iteration = 0

    def step(self, params, grads):
        """Update parameters given gradients. Must be implemented by subclass."""
        raise NotImplementedError

    def reset(self):
        """Reset optimizer state."""
        self.iteration = 0

class SGD(Optimizer):
    """Stochastic Gradient Descent."""

    def step(self, params, grads):
        return params - self.learning_rate * grads

class Momentum(Optimizer):
    """SGD with momentum."""

    def __init__(self, learning_rate=0.01, beta=0.9):
        super().__init__(learning_rate)
        self.beta = beta
        self.velocity = None

    def step(self, params, grads):
        if self.velocity is None:
            self.velocity = np.zeros_like(params)

        self.velocity = self.beta * self.velocity + (1 - self.beta) * grads
        return params - self.learning_rate * self.velocity

    def reset(self):
        super().reset()
        self.velocity = None

class Nesterov(Optimizer):
    """Nesterov Accelerated Gradient."""

    def __init__(self, learning_rate=0.01, beta=0.9):
        super().__init__(learning_rate)
        self.beta = beta
        self.velocity = None

    def step(self, params, grads):
        if self.velocity is None:
            self.velocity = np.zeros_like(params)

        velocity_old = self.velocity.copy()
        self.velocity = self.beta * self.velocity + (1 - self.beta) * grads
        return params - self.learning_rate * (self.beta * self.velocity + (1 - self.beta) * grads)

    def reset(self):
        super().reset()
        self.velocity = None

class RMSprop(Optimizer):
    """RMSprop optimizer."""

    def __init__(self, learning_rate=0.01, beta=0.9, epsilon=1e-8):
        super().__init__(learning_rate)
        self.beta = beta
        self.epsilon = epsilon
        self.squared_grads = None

    def step(self, params, grads):
        if self.squared_grads is None:
            self.squared_grads = np.zeros_like(params)

        self.squared_grads = (self.beta * self.squared_grads +
                             (1 - self.beta) * grads**2)

        return params - self.learning_rate * grads / (np.sqrt(self.squared_grads) + self.epsilon)

    def reset(self):
        super().reset()
        self.squared_grads = None

class Adam(Optimizer):
    """Adam optimizer."""

    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):
        super().__init__(learning_rate)
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.m = None
        self.v = None
        self.t = 0

    def step(self, params, grads):
        if self.m is None:
            self.m = np.zeros_like(params)
            self.v = np.zeros_like(params)

        self.t += 1

        # Update biased first and second moments
        self.m = self.beta1 * self.m + (1 - self.beta1) * grads
        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2

        # Bias correction
        m_hat = self.m / (1 - self.beta1**self.t)
        v_hat = self.v / (1 - self.beta2**self.t)

        return params - self.learning_rate * m_hat / (np.sqrt(v_hat) + self.epsilon)

    def reset(self):
        super().reset()
        self.m = None
        self.v = None
        self.t = 0

class AdamW(Adam):
    """AdamW: Adam with decoupled weight decay."""

    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999,
                 epsilon=1e-8, weight_decay=0.01):
        super().__init__(learning_rate, beta1, beta2, epsilon)
        self.weight_decay = weight_decay

    def step(self, params, grads):
        # Get Adam update
        params_new = super().step(params, grads)

        # Add weight decay (applied to parameters, not gradients)
        params_new = params_new - self.learning_rate * self.weight_decay * params

        return params_new

# ============================================================================
# Visualization Functions (Phase 1)
# ============================================================================

def visualize_function(func, x_range=(-5, 5), y_range=(-5, 5), resolution=100):
    """Create 2D contour and 3D surface plots of a function."""
    x = np.linspace(x_range[0], x_range[1], resolution)
    y = np.linspace(y_range[0], y_range[1], resolution)
    X, Y = np.meshgrid(x, y)

    Z = np.zeros_like(X)
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):
            Z[i, j] = func(np.array([X[i, j], Y[i, j]]))

    fig = plt.figure(figsize=(14, 5))

    # 2D contour plot
    ax1 = fig.add_subplot(121)
    contour = ax1.contour(X, Y, Z, levels=30, cmap='viridis')
    ax1.clabel(contour, inline=True, fontsize=8)
    ax1.set_xlabel('x‚ÇÄ')
    ax1.set_ylabel('x‚ÇÅ')
    ax1.set_title('Contour Plot')
    ax1.grid(True, alpha=0.3)

    # 3D surface plot
    ax2 = fig.add_subplot(122, projection='3d')
    surf = ax2.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8,
                           edgecolor='none', antialiased=True)
    ax2.set_xlabel('x‚ÇÄ')
    ax2.set_ylabel('x‚ÇÅ')
    ax2.set_zlabel('f(x)')
    ax2.set_title('3D Surface Plot')
    fig.colorbar(surf, ax=ax2, shrink=0.5, aspect=5)

    plt.tight_layout()
    return fig

# ============================================================================
# Optimization Runner (Phase 2 & 3)
# ============================================================================

def run_optimizer(func, grad_func, initial, optimizer, n_iterations=500):
    """Run a single optimizer and record trajectory."""
    params = initial.copy()
    trajectory = [params.copy()]
    losses = [func(params)]

    optimizer.reset()

    for i in range(n_iterations):
        grads = grad_func(params)
        params = optimizer.step(params, grads)

        trajectory.append(params.copy())
        losses.append(func(params))

    return {
        'trajectory': np.array(trajectory),
        'losses': np.array(losses),
        'final_params': params,
        'final_loss': losses[-1]
    }

def compare_optimizers(func, grad_func, initial, optimizers, n_iterations=500):
    """Compare multiple optimizers on the same function."""
    results = {}

    for name, optimizer in optimizers.items():
        print(f"Running {name}...")
        results[name] = run_optimizer(func, grad_func, initial, optimizer, n_iterations)

    return results

# ============================================================================
# Visualization for Comparison (Phase 3)
# ============================================================================

def visualize_comparison(func, results, x_range=(-5, 5), y_range=(-5, 5), resolution=100):
    """Visualize optimization trajectories for multiple optimizers."""
    # Create contour plot
    x = np.linspace(x_range[0], x_range[1], resolution)
    y = np.linspace(y_range[0], y_range[1], resolution)
    X, Y = np.meshgrid(x, y)

    Z = np.zeros_like(X)
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):
            Z[i, j] = func(np.array([X[i, j], Y[i, j]]))

    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Trajectory plot
    ax1 = axes[0]
    contour = ax1.contour(X, Y, Z, levels=30, cmap='gray', alpha=0.3)

    colors = plt.cm.tab10(np.linspace(0, 1, len(results)))
    for (name, result), color in zip(results.items(), colors):
        traj = result['trajectory']
        ax1.plot(traj[:, 0], traj[:, 1], 'o-', label=name,
                color=color, markersize=3, linewidth=2, alpha=0.7)
        ax1.plot(traj[0, 0], traj[0, 1], 'o', color=color,
                markersize=10, markeredgecolor='black', markeredgewidth=2)
        ax1.plot(traj[-1, 0], traj[-1, 1], '*', color=color,
                markersize=15, markeredgecolor='black', markeredgewidth=2)

    ax1.set_xlabel('x‚ÇÄ', fontsize=12)
    ax1.set_ylabel('x‚ÇÅ', fontsize=12)
    ax1.set_title('Optimization Trajectories', fontsize=14, fontweight='bold')
    ax1.legend(loc='best')
    ax1.grid(True, alpha=0.3)

    # Convergence plot
    ax2 = axes[1]
    for (name, result), color in zip(results.items(), colors):
        losses = result['losses']
        ax2.semilogy(losses, label=name, color=color, linewidth=2)

    ax2.set_xlabel('Iteration', fontsize=12)
    ax2.set_ylabel('Loss (log scale)', fontsize=12)
    ax2.set_title('Convergence Curves', fontsize=14, fontweight='bold')
    ax2.legend(loc='best')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    return fig

def print_summary_table(results):
    """Print a summary table of optimization results."""
    print("\n" + "="*80)
    print(f"{'Optimizer':<15} {'Final Loss':<15} {'Final x‚ÇÄ':<15} {'Final x‚ÇÅ':<15}")
    print("="*80)

    for name, result in results.items():
        final_loss = result['final_loss']
        final_params = result['final_params']
        print(f"{name:<15} {final_loss:<15.6f} {final_params[0]:<15.6f} {final_params[1]:<15.6f}")

    print("="*80 + "\n")

# ============================================================================
# Example Usage
# ============================================================================

if __name__ == "__main__":
    # Initialize test functions
    funcs = TestFunctions()

    # Example 1: Visualize Rosenbrock function
    print("Visualizing Rosenbrock function...")
    fig = visualize_function(funcs.rosenbrock, x_range=(-2, 2), y_range=(-1, 3))
    plt.savefig('rosenbrock_landscape.png', dpi=150)
    plt.show()

    # Example 2: Compare optimizers on Rosenbrock
    print("\nComparing optimizers on Rosenbrock...")

    # Define optimizers
    optimizers = {
        'SGD': SGD(learning_rate=0.001),
        'Momentum': Momentum(learning_rate=0.002, beta=0.9),
        'Nesterov': Nesterov(learning_rate=0.002, beta=0.9),
        'RMSprop': RMSprop(learning_rate=0.01, beta=0.9),
        'Adam': Adam(learning_rate=0.01),
        'AdamW': AdamW(learning_rate=0.01, weight_decay=0.01)
    }

    # Starting point
    initial = np.array([-1.5, 2.5])

    # Run comparison
    results = compare_optimizers(
        funcs.rosenbrock,
        funcs.rosenbrock_grad,
        initial,
        optimizers,
        n_iterations=500
    )

    # Visualize
    fig = visualize_comparison(funcs.rosenbrock, results, x_range=(-2, 2), y_range=(-1, 3))
    plt.savefig('optimizer_comparison_rosenbrock.png', dpi=150)
    plt.show()

    # Print summary
    print_summary_table(results)

    # Example 3: Compare on Ackley function
    print("\nComparing optimizers on Ackley...")

    initial_ackley = np.array([4.0, 4.0])
    results_ackley = compare_optimizers(
        funcs.ackley,
        funcs.ackley_grad,
        initial_ackley,
        optimizers,
        n_iterations=500
    )

    fig = visualize_comparison(funcs.ackley, results_ackley, x_range=(-5, 5), y_range=(-5, 5))
    plt.savefig('optimizer_comparison_ackley.png', dpi=150)
    plt.show()

    print_summary_table(results_ackley)
\`\`\`

## Key Features

This complete implementation provides:

1. **Modular Design**: Separate classes for test functions and optimizers
2. **Easy Extension**: Base `Optimizer` class makes adding new optimizers simple
3. **Comprehensive Visualization**: Contour plots, 3D surfaces, trajectories, and convergence curves
4. **Batch Comparison**: Compare multiple optimizers simultaneously
5. **Clean Output**: Summary tables and high-quality plots

## Usage Examples

**Test a new optimizer:**
\`\`\`python
# Add your custom optimizer
class MyOptimizer(Optimizer):
    def step(self, params, grads):
        # Your optimization logic here
        return updated_params

optimizers['MyOptimizer'] = MyOptimizer(learning_rate=0.01)
\`\`\`

**Test on a new function:**
\`\`\`python
# Add your custom function
def my_func(x):
    return your_expression

def my_func_grad(x):
    return gradient_array

results = compare_optimizers(my_func, my_func_grad, initial, optimizers)
\`\`\`

**Quick benchmark:**
\`\`\`python
# Test all optimizers on all functions
test_cases = [
    ('Rosenbrock', funcs.rosenbrock, funcs.rosenbrock_grad, np.array([-1.5, 2.5])),
    ('Ackley', funcs.ackley, funcs.ackley_grad, np.array([4.0, 4.0])),
    ('Saddle', funcs.saddle, funcs.saddle_grad, np.array([-1.1, 1.2])),
]

for name, func, grad, init in test_cases:
    print(f"\n{'='*80}")
    print(f"Testing on {name} function")
    print('='*80)
    results = compare_optimizers(func, grad, init, optimizers)
    print_summary_table(results)
\`\`\`

</details>

---

## üéØ Milestones & Validation

<div class="milestone-box">

### Milestone 1: Visualizations Working

**Success Criteria:**
- Can visualize all 5 test functions
- Contour and 3D plots look correct
- Can identify features (minima, saddle points, valleys)

**Validation:**
- Rosenbrock shows narrow valley
- Saddle function shows saddle at origin
- Ackley shows many local minima

</div>

<div class="milestone-box">

### Milestone 2: Optimizers Implemented

**Success Criteria:**
- All 5+ optimizers work correctly
- Can run on simple quadratic (should converge to [0,0])
- Momentum smooths oscillations visibly

**Validation:**
- Test on sphere function: all should reach origin
- SGD vs Momentum on Rosenbrock: Momentum should be smoother
- Adam should converge faster than SGD on most functions

</div>

<div class="milestone-box">

### Milestone 3: Comparative Analysis Complete

**Success Criteria:**
- Ran all optimizers on all test functions
- Generated trajectory plots for each
- Have convergence curves and statistics

**Validation:**
- Can explain why Adam wins on some functions
- Can explain why Momentum helps on Rosenbrock
- Can identify when SGD is sufficient vs when adaptive methods needed

</div>

---

## üìä Suggested Experiments

### Experiment 1: Learning Rate Sensitivity

**Question:** How sensitive is each optimizer to learning rate?

**Procedure:**
1. Pick one function (e.g., Rosenbrock)
2. Try learning rates: [0.001, 0.01, 0.1, 1.0]
3. Plot convergence for each

**What to observe:**
- Which optimizer is most robust?
- At what LR does each diverge?

### Experiment 2: Momentum Values

**Question:** How does momentum Œ≤ affect convergence?

**Procedure:**
1. Try Œ≤ = [0.0, 0.5, 0.9, 0.99, 0.999]
2. Compare on narrow valley (Rosenbrock)

**What to observe:**
- Sweet spot for Œ≤?
- Too high: overshooting?
- Too low: slow like vanilla SGD?

### Experiment 3: Saddle Point Escape

**Question:** Which optimizer escapes saddle points fastest?

**Procedure:**
1. Use saddle function
2. Start exactly at saddle point + small noise
3. Count iterations to escape

**What to observe:**
- Adaptive methods (Adam, RMSprop) add noise ‚Üí faster escape?

---

## ‚úÖ Final Checklist

Before considering this project complete:

- [ ] Implemented 5+ test functions with analytical gradients
- [ ] Implemented 5+ optimizers from scratch
- [ ] Created visualization framework (contours + 3D + trajectories)
- [ ] Ran comprehensive comparison experiments
- [ ] Documented findings with plots and tables
- [ ] (Optional) Implemented learning rate schedules
- [ ] Can explain when to use which optimizer

**Most importantly:**
- [ ] You **understand** why momentum helps
- [ ] You **understand** what adaptive learning rates solve
- [ ] You have **intuition** for optimization dynamics
- [ ] You can **debug** optimization issues in practice

---

Good luck! Remember: this is about **understanding optimization dynamics**, not just implementing formulas. Experiment, visualize, and build intuition! üöÄ
`;

        // Render markdown
        document.getElementById('guide-content').innerHTML = marked.parse(markdown);

        // Make checkboxes interactive and persistent
        const checkboxes = document.querySelectorAll('input[type="checkbox"]');
        const storageKey = 'project_module3_checklist';

        // Load saved state
        const saved = localStorage.getItem(storageKey);
        const checkedState = saved ? JSON.parse(saved) : {};

        checkboxes.forEach((checkbox, index) => {
            const checkboxId = `checkbox_${index}`;
            checkbox.id = checkboxId;

            // Restore checked state
            if (checkedState[checkboxId]) {
                checkbox.checked = true;
            }

            // Save state on change
            checkbox.addEventListener('change', function() {
                checkedState[checkboxId] = this.checked;
                localStorage.setItem(storageKey, JSON.stringify(checkedState));
            });
        });
    </script>
</body>
</html>
