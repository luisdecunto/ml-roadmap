<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Micrograd (Autograd Engine) Exercises - ML Roadmap</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .exercise-item {
            border-left: 4px solid #e5e7eb;
            padding-left: 1rem;
            margin-bottom: 1.5rem;
            transition: all 0.2s;
        }
        .exercise-item.completed {
            border-left-color: #10b981;
            opacity: 0.7;
        }
        .exercise-item h3 {
            font-size: 1.25rem;
            font-weight: 600;
            color: #374151;
            margin-bottom: 0.5rem;
        }
        .exercise-item.completed h3 {
            text-decoration: line-through;
            color: #9ca3af;
        }
        .section-header {
            font-size: 1.5rem;
            font-weight: 700;
            color: #1f2937;
            margin-top: 2rem;
            margin-bottom: 1rem;
            border-bottom: 2px solid #10b981;
            padding-bottom: 0.5rem;
        }
        .content-text {
            color: #4b5563;
            line-height: 1.6;
            margin-bottom: 0.75rem;
        }
        .content-text.completed {
            color: #9ca3af;
        }
        pre {
            background-color: #1f2937;
            color: #f3f4f6;
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin: 1rem 0;
        }
        code {
            font-family: 'Courier New', monospace;
        }
        .checkbox-custom {
            width: 1.25rem;
            height: 1.25rem;
            cursor: pointer;
            accent-color: #10b981;
        }
    </style>
</head>
<body class="bg-gradient-to-br from-emerald-50 via-teal-50 to-green-50 min-h-screen">
    <div class="max-w-5xl mx-auto p-4 md:p-8">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <div class="flex items-center justify-between mb-4">
                <h1 class="text-3xl font-bold text-gray-800">Micrograd (Autograd Engine) Exercises</h1>
                <div class="flex space-x-2">
                    <a href="../solutions/micrograd_solutions.md" class="px-4 py-2 bg-emerald-600 hover:bg-emerald-700 text-white rounded-lg text-sm font-semibold">
                        View Solutions
                    </a>
                    <a href="../../index.html" class="px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white rounded-lg text-sm font-semibold">
                        ‚Üê Back to Roadmap
                    </a>
                </div>
            </div>
            <div class="flex items-center justify-between">
                <div class="flex items-center space-x-4 text-sm text-gray-600">
                    <span>‚è±Ô∏è Time: 4-6 hours</span>
                    <span>üìä Difficulty: Intermediate-Advanced</span>
                </div>
                <div class="text-right">
                    <div id="sync-status" class="text-xs text-gray-500 mb-1"></div>
                    <div class="text-sm text-gray-600 mb-1">Progress: <span id="progress-text" class="font-bold text-emerald-600">0%</span></div>
                    <div class="w-48 bg-gray-200 rounded-full h-2">
                        <div id="progress-bar" class="bg-emerald-600 h-2 rounded-full transition-all" style="width: 0%"></div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Content -->
        <div class="bg-white rounded-lg shadow-lg p-8">
            <div class="mb-6 p-4 bg-blue-50 border-l-4 border-blue-500 rounded">
                <p class="text-sm text-gray-700">
                    <strong>Prerequisites:</strong> Complete the micrograd demo.ipynb notebook first. These exercises test your understanding
                    of automatic differentiation, backpropagation, and building neural networks from scratch.
                </p>
            </div>

            <!-- Section 1: Understanding the Value Class -->
            <h2 class="section-header">Section 1: Understanding the Value Class & Forward Pass</h2>

            <div class="exercise-item" data-exercise-id="micrograd-1.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-1.1')">
                    <div class="flex-1">
                        <h3>Exercise 1.1: Manual Forward Pass</h3>
                        <div class="content-text">
                            Given the following computation graph, calculate the output value manually:
                        </div>
                        <pre><code>a = Value(2.0)
b = Value(-3.0)
c = Value(10.0)
d = a * b + c</code></pre>
                        <div class="content-text">
                            What is <code>d.data</code>?
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-1.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-1.2')">
                    <div class="flex-1">
                        <h3>Exercise 1.2: Complex Expression</h3>
                        <div class="content-text">
                            Compute the forward pass for:
                        </div>
                        <pre><code>x = Value(3.0)
y = Value(-2.0)
z = x**2 + 2*x*y + y**2</code></pre>
                        <div class="content-text">
                            What is <code>z.data</code>?
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-1.3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-1.3')">
                    <div class="flex-1">
                        <h3>Exercise 1.3: ReLU Activation</h3>
                        <div class="content-text">
                            Implement the forward pass manually for:
                        </div>
                        <pre><code>a = Value(-5.0)
b = Value(3.0)
c = a.relu()
d = b.relu()
e = c + d</code></pre>
                        <div class="content-text">
                            What are <code>c.data</code>, <code>d.data</code>, and <code>e.data</code>?
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 2: Manual Backpropagation -->
            <h2 class="section-header">Section 2: Manual Backpropagation</h2>

            <div class="exercise-item" data-exercise-id="micrograd-2.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-2.1')">
                    <div class="flex-1">
                        <h3>Exercise 2.1: Simple Chain Rule</h3>
                        <div class="content-text">
                            Given:
                        </div>
                        <pre><code>a = Value(2.0)
b = Value(3.0)
c = a * b
c.backward()</code></pre>
                        <div class="content-text">
                            Calculate manually: <code>a.grad</code> and <code>b.grad</code>
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-2.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-2.2')">
                    <div class="flex-1">
                        <h3>Exercise 2.2: Addition and Multiplication</h3>
                        <div class="content-text">
                            For the computation from Exercise 1.1:
                        </div>
                        <pre><code>a = Value(2.0)
b = Value(-3.0)
c = Value(10.0)
d = a * b + c
d.backward()</code></pre>
                        <div class="content-text">
                            Calculate manually: <code>a.grad</code>, <code>b.grad</code>, and <code>c.grad</code>
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-2.3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-2.3')">
                    <div class="flex-1">
                        <h3>Exercise 2.3: Power Function Gradient</h3>
                        <div class="content-text">
                            Given:
                        </div>
                        <pre><code>x = Value(3.0)
y = x**3
y.backward()</code></pre>
                        <div class="content-text">
                            Calculate manually: <code>x.grad</code> (Hint: d/dx(x¬≥) = 3x¬≤)
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-2.4">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-2.4')">
                    <div class="flex-1">
                        <h3>Exercise 2.4: ReLU Gradient</h3>
                        <div class="content-text">
                            For the ReLU computation:
                        </div>
                        <pre><code>a = Value(-2.0)
b = Value(3.0)
c = a.relu()
d = b.relu()
e = c + d
e.backward()</code></pre>
                        <div class="content-text">
                            Calculate manually: <code>a.grad</code> and <code>b.grad</code> (Remember: ReLU derivative is 0 if x < 0, else 1)
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 3: Understanding Computational Graphs -->
            <h2 class="section-header">Section 3: Understanding Computational Graphs</h2>

            <div class="exercise-item" data-exercise-id="micrograd-3.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-3.1')">
                    <div class="flex-1">
                        <h3>Exercise 3.1: Draw the Computation Graph</h3>
                        <div class="content-text">
                            On paper, draw the complete computation graph (nodes and edges) for:
                        </div>
                        <pre><code>a = Value(2.0)
b = Value(-3.0)
c = a + b
d = a * b
e = c * d</code></pre>
                        <div class="content-text">
                            Label each node with the operation and its value. Draw edges showing dependencies.
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-3.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-3.2')">
                    <div class="flex-1">
                        <h3>Exercise 3.2: Topological Sort Understanding</h3>
                        <div class="content-text">
                            For the graph in 3.1, write down the topological order in which backpropagation visits the nodes.
                            Explain why this order is necessary.
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 4: Building a Neuron from Scratch -->
            <h2 class="section-header">Section 4: Building a Neuron from Scratch</h2>

            <div class="exercise-item" data-exercise-id="micrograd-4.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-4.1')">
                    <div class="flex-1">
                        <h3>Exercise 4.1: Single Neuron Forward Pass</h3>
                        <div class="content-text">
                            A neuron computes: <code>output = tanh(w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b)</code>
                            <br><br>
                            Given: w‚ÇÅ = 0.5, w‚ÇÇ = -0.3, b = 0.1, x‚ÇÅ = 2.0, x‚ÇÇ = 3.0
                            <br><br>
                            Calculate the output manually (use tanh approximation or calculator).
                            Then implement this in micrograd using Value objects.
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-4.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-4.2')">
                    <div class="flex-1">
                        <h3>Exercise 4.2: Neuron Gradient Computation</h3>
                        <div class="content-text">
                            For the neuron in 4.1, run backpropagation and calculate:
                        </div>
                        <pre><code>output.backward()</code></pre>
                        <div class="content-text">
                            What are the gradients with respect to w‚ÇÅ, w‚ÇÇ, and b? Verify your manual calculation matches micrograd.
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-4.3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-4.3')">
                    <div class="flex-1">
                        <h3>Exercise 4.3: Build a Custom Neuron Class</h3>
                        <div class="content-text">
                            Without looking at micrograd's nn.py, implement your own Neuron class with:
                        </div>
                        <pre><code>class Neuron:
    def __init__(self, nin):
        # Initialize random weights and bias as Value objects
        pass

    def __call__(self, x):
        # Compute activation: sum(wi*xi) + b, then apply tanh
        pass

    def parameters(self):
        # Return list of all weights and bias
        pass</code></pre>
                        <div class="content-text">
                            Test it with a 3-input neuron and verify gradients flow correctly.
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 5: Multi-Layer Perceptron (MLP) -->
            <h2 class="section-header">Section 5: Multi-Layer Perceptron (MLP)</h2>

            <div class="exercise-item" data-exercise-id="micrograd-5.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-5.1')">
                    <div class="flex-1">
                        <h3>Exercise 5.1: Build a Layer Class</h3>
                        <div class="content-text">
                            Implement a Layer class that contains multiple neurons:
                        </div>
                        <pre><code>class Layer:
    def __init__(self, nin, nout):
        # Create nout neurons, each with nin inputs
        pass

    def __call__(self, x):
        # Apply all neurons to input x
        pass

    def parameters(self):
        # Return all parameters from all neurons
        pass</code></pre>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-5.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-5.2')">
                    <div class="flex-1">
                        <h3>Exercise 5.2: Build an MLP Class</h3>
                        <div class="content-text">
                            Implement a complete MLP (Multi-Layer Perceptron):
                        </div>
                        <pre><code>class MLP:
    def __init__(self, nin, nouts):
        # nouts is a list: [hidden_size1, hidden_size2, ..., output_size]
        # Create layers connecting: nin -> nouts[0] -> nouts[1] -> ... -> nouts[-1]
        pass

    def __call__(self, x):
        # Forward pass through all layers
        pass

    def parameters(self):
        # Return all parameters from all layers
        pass</code></pre>
                        <div class="content-text">
                            Test with a 3-layer MLP: MLP(2, [4, 4, 1])
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-5.3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-5.3')">
                    <div class="flex-1">
                        <h3>Exercise 5.3: Count Parameters</h3>
                        <div class="content-text">
                            For an MLP with architecture [3, 4, 4, 1]:
                            <br>‚Ä¢ How many parameters (weights + biases) does it have?
                            <br>‚Ä¢ Calculate this manually, then verify with <code>len(mlp.parameters())</code>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 6: Loss Functions -->
            <h2 class="section-header">Section 6: Loss Functions & Training</h2>

            <div class="exercise-item" data-exercise-id="micrograd-6.1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-6.1')">
                    <div class="flex-1">
                        <h3>Exercise 6.1: Mean Squared Error (MSE)</h3>
                        <div class="content-text">
                            Implement MSE loss using micrograd Value objects:
                        </div>
                        <pre><code>def mse_loss(predictions, targets):
    # predictions and targets are lists of Value objects
    # Return: sum((pred - target)^2) / len(predictions)
    pass</code></pre>
                        <div class="content-text">
                            Test with predictions = [1.5, 2.0, 3.5] and targets = [1.0, 2.0, 3.0]
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-6.2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-6.2')">
                    <div class="flex-1">
                        <h3>Exercise 6.2: Gradient Descent Step</h3>
                        <div class="content-text">
                            Implement a single gradient descent update:
                        </div>
                        <pre><code># Given: loss.backward() has been called, learning_rate = 0.01
for p in mlp.parameters():
    p.data += # YOUR CODE HERE
    p.grad = 0.0  # Zero gradients</code></pre>
                        <div class="content-text">
                            Fill in the update rule. Why do we need to zero gradients?
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-6.3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-6.3')">
                    <div class="flex-1">
                        <h3>Exercise 6.3: Simple Training Loop</h3>
                        <div class="content-text">
                            Create a simple dataset and train an MLP for 20 iterations:
                        </div>
                        <pre><code># Dataset: learn XOR function
xs = [[0,0], [0,1], [1,0], [1,1]]
ys = [0, 1, 1, 0]

# Create MLP: 2 inputs -> 4 hidden -> 1 output
# Train for 20 iterations
# Print loss every 5 iterations</code></pre>
                        <div class="content-text">
                            Does the loss decrease? (Note: XOR is hard, loss may not reach zero)
                        </div>
                    </div>
                </div>
            </div>

            <!-- Section 7: Advanced Challenges -->
            <h2 class="section-header">Section 7: Advanced Challenges</h2>

            <div class="exercise-item" data-exercise-id="micrograd-challenge-1">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-challenge-1')">
                    <div class="flex-1">
                        <h3>Challenge 1: Implement tanh() in Value Class</h3>
                        <div class="content-text">
                            Add a tanh() method to the Value class with proper backward():
                        </div>
                        <pre><code>def tanh(self):
    # Forward: tanh(x) = (e^x - e^-x) / (e^x + e^-x)
    # Backward: d/dx tanh(x) = 1 - tanh¬≤(x)
    pass</code></pre>
                        <div class="content-text">
                            Test it and verify gradients with manual calculation.
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-challenge-2">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-challenge-2')">
                    <div class="flex-1">
                        <h3>Challenge 2: Implement Sigmoid Activation</h3>
                        <div class="content-text">
                            Add sigmoid() to Value class:
                        </div>
                        <pre><code>def sigmoid(self):
    # Forward: œÉ(x) = 1 / (1 + e^-x)
    # Backward: d/dx œÉ(x) = œÉ(x) * (1 - œÉ(x))
    pass</code></pre>
                        <div class="content-text">
                            Modify your Neuron class to use sigmoid instead of tanh and compare training behavior.
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-challenge-3">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-challenge-3')">
                    <div class="flex-1">
                        <h3>Challenge 3: Binary Classification with Micrograd</h3>
                        <div class="content-text">
                            Create a 2D dataset (make_moons or make_circles) and train a classifier:
                            <br>‚Ä¢ Generate 100 points with 2 classes
                            <br>‚Ä¢ Build an MLP: [2, 16, 16, 1]
                            <br>‚Ä¢ Use sigmoid output and binary cross-entropy loss
                            <br>‚Ä¢ Train for 100 iterations
                            <br>‚Ä¢ Plot decision boundary (optional but recommended!)
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise-item" data-exercise-id="micrograd-challenge-4">
                <div class="flex items-start space-x-3">
                    <input type="checkbox" class="checkbox-custom mt-1" onchange="toggleExercise('micrograd-challenge-4')">
                    <div class="flex-1">
                        <h3>Challenge 4: Compare with PyTorch</h3>
                        <div class="content-text">
                            Build the same network in both micrograd and PyTorch:
                            <br>‚Ä¢ Same architecture, same initial weights (copy them over)
                            <br>‚Ä¢ Same input data
                            <br>‚Ä¢ Run forward and backward pass
                            <br>‚Ä¢ Compare gradients - they should match to many decimal places!
                        </div>
                        <div class="content-text">
                            This demonstrates that micrograd implements the same math as PyTorch.
                        </div>
                    </div>
                </div>
            </div>

        </div>

        <!-- Footer -->
        <div class="bg-white rounded-lg shadow-lg p-6 mt-6">
            <h3 class="text-lg font-semibold text-gray-800 mb-3">üìö Additional Resources</h3>
            <ul class="space-y-2 text-sm text-gray-600">
                <li>‚Ä¢ <a href="https://github.com/karpathy/micrograd" class="text-indigo-600 hover:underline">Micrograd GitHub Repository</a></li>
                <li>‚Ä¢ <a href="https://www.youtube.com/watch?v=VMj-3S1tku0" class="text-indigo-600 hover:underline">Karpathy's Video Lecture (2h)</a></li>
                <li>‚Ä¢ Work through demo.ipynb first before attempting these exercises</li>
                <li>‚Ä¢ Try to solve by hand first, then verify with code</li>
            </ul>
        </div>

        <!-- Navigation -->
        <div class="text-center mt-6 text-sm text-gray-600">
            <a href="../solutions/micrograd_solutions.md" class="text-indigo-600 hover:text-indigo-700 font-semibold">
                View Solutions ‚Üí
            </a>
            <span>|</span>
            <a href="../../index.html" class="text-indigo-600 hover:text-indigo-700 font-semibold">
                ‚Üê Back to ML Roadmap
            </a>
        </div>
    </div>

    <script>
        // GitHub sync configuration
        const GITHUB_USERNAME = 'luisdecunto';
        const GITHUB_REPO = 'ml-roadmap';
        const GITHUB_BRANCH = 'main';
        const PROGRESS_FILE = 'progress.json';

        let fileSha = null;
        let isEditMode = false;

        // Update sync status display
        function updateSyncStatus(status) {
            const statusElement = document.getElementById('sync-status');
            if (statusElement) {
                if (status === 'edit') {
                    statusElement.textContent = '‚úèÔ∏è Edit Mode';
                    statusElement.className = 'text-xs text-emerald-600 mb-1 font-semibold';
                } else if (status === 'view') {
                    statusElement.textContent = 'üëÅÔ∏è View Only';
                    statusElement.className = 'text-xs text-gray-500 mb-1';
                } else if (status === 'saving') {
                    statusElement.textContent = 'üíæ Saving...';
                    statusElement.className = 'text-xs text-blue-600 mb-1';
                } else if (status === 'saved') {
                    statusElement.textContent = '‚úÖ Saved';
                    statusElement.className = 'text-xs text-emerald-600 mb-1';
                    setTimeout(() => updateSyncStatus(isEditMode ? 'edit' : 'view'), 2000);
                }
            }
        }

        // Sync exercise completions from GitHub on page load
        async function syncFromGitHub() {
            try {
                const response = await fetch(`https://api.github.com/repos/${GITHUB_USERNAME}/${GITHUB_REPO}/contents/${PROGRESS_FILE}`, {
                    headers: {
                        'Accept': 'application/vnd.github.v3+json'
                    }
                });

                if (response.ok) {
                    const data = await response.json();
                    fileSha = data.sha; // Store SHA for updates
                    const content = JSON.parse(atob(data.content));

                    if (content.exerciseCompletions) {
                        // Merge with existing localStorage (prefer GitHub data)
                        localStorage.setItem('exercise-completions', JSON.stringify(content.exerciseCompletions));
                    }
                }
            } catch (error) {
                console.log('Could not sync from GitHub, using local data:', error);
            }
        }

        // Save exercise completions to GitHub
        async function saveToGitHub() {
            const token = localStorage.getItem('githubToken');
            if (!token || !fileSha) {
                console.log('Cannot save to GitHub:', { hasToken: !!token, hasFileSha: !!fileSha });
                return;
            }

            console.log('Saving exercise progress to GitHub...');

            try {
                // Get current progress data
                const getCurrentProgress = await fetch(`https://api.github.com/repos/${GITHUB_USERNAME}/${GITHUB_REPO}/contents/${PROGRESS_FILE}`, {
                    headers: {
                        'Accept': 'application/vnd.github.v3+json',
                        'Authorization': `token ${token}`
                    }
                });

                if (getCurrentProgress.ok) {
                    const currentData = await getCurrentProgress.json();
                    const currentContent = JSON.parse(atob(currentData.content));
                    fileSha = currentData.sha; // Update SHA

                    // Update only exerciseCompletions
                    const exerciseCompletions = JSON.parse(localStorage.getItem('exercise-completions') || '{}');
                    currentContent.exerciseCompletions = exerciseCompletions;
                    currentContent.lastUpdated = new Date().toISOString();

                    // Save back to GitHub
                    const content = btoa(JSON.stringify(currentContent, null, 2));
                    const response = await fetch(`https://api.github.com/repos/${GITHUB_USERNAME}/${GITHUB_REPO}/contents/${PROGRESS_FILE}`, {
                        method: 'PUT',
                        headers: {
                            'Authorization': `token ${token}`,
                            'Accept': 'application/vnd.github.v3+json',
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            message: 'Update exercise progress',
                            content: content,
                            sha: fileSha,
                            branch: GITHUB_BRANCH
                        })
                    });

                    if (response.ok) {
                        const data = await response.json();
                        fileSha = data.content.sha;
                        console.log('‚úÖ Progress saved to GitHub successfully');
                    } else {
                        console.error('Failed to save to GitHub:', response.status, await response.text());
                    }
                } else {
                    console.error('Failed to fetch current progress:', getCurrentProgress.status);
                }
            } catch (error) {
                console.error('‚ùå Error saving to GitHub:', error);
            }
        }

        // Load completion state from localStorage
        function loadCompletionState() {
            const state = JSON.parse(localStorage.getItem('exercise-completions') || '{}');
            let completed = 0;
            let total = 0;

            document.querySelectorAll('.exercise-item').forEach(item => {
                const id = item.getAttribute('data-exercise-id');
                const checkbox = item.querySelector('input[type="checkbox"]');
                total++;

                if (state[id]) {
                    checkbox.checked = true;
                    item.classList.add('completed');
                    item.querySelectorAll('.content-text').forEach(el => el.classList.add('completed'));
                    completed++;
                }
            });

            updateProgress(completed, total);
        }

        // Toggle exercise completion
        function toggleExercise(exerciseId) {
            // Prevent changes in view-only mode
            if (!isEditMode) {
                alert('‚ö†Ô∏è View Only Mode\n\nTo save progress, you need to set up your GitHub token on the main roadmap page.');
                return;
            }

            const state = JSON.parse(localStorage.getItem('exercise-completions') || '{}');
            state[exerciseId] = !state[exerciseId];

            if (!state[exerciseId]) {
                delete state[exerciseId];
            }

            localStorage.setItem('exercise-completions', JSON.stringify(state));

            // Show saving status
            updateSyncStatus('saving');

            // Save to GitHub
            saveToGitHub().then(() => {
                updateSyncStatus('saved');
            });

            // Notify other windows/tabs about the change
            window.dispatchEvent(new StorageEvent('storage', {
                key: 'exercise-completions',
                newValue: JSON.stringify(state),
                url: window.location.href,
                storageArea: localStorage
            }));

            // Update UI
            const item = document.querySelector(`[data-exercise-id="${exerciseId}"]`);
            if (state[exerciseId]) {
                item.classList.add('completed');
                item.querySelectorAll('.content-text').forEach(el => el.classList.add('completed'));
            } else {
                item.classList.remove('completed');
                item.querySelectorAll('.content-text').forEach(el => el.classList.remove('completed'));
            }

            // Recalculate progress
            loadCompletionState();
        }

        // Update progress bar
        function updateProgress(completed, total) {
            const percentage = total > 0 ? Math.round((completed / total) * 100) : 0;
            document.getElementById('progress-bar').style.width = percentage + '%';
            document.getElementById('progress-text').textContent = percentage + '%';
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', async () => {
            // Check if user has a token (edit mode)
            const token = localStorage.getItem('githubToken');
            isEditMode = !!token;

            console.log('üîç Debug Info:', {
                hasToken: !!token,
                tokenLength: token ? token.length : 0,
                isEditMode: isEditMode,
                allLocalStorageKeys: Object.keys(localStorage)
            });

            await syncFromGitHub();
            loadCompletionState();

            // Set initial sync status
            updateSyncStatus(isEditMode ? 'edit' : 'view');

            // Disable checkboxes in view-only mode
            if (!isEditMode) {
                document.querySelectorAll('input[type="checkbox"]').forEach(checkbox => {
                    checkbox.disabled = true;
                    checkbox.style.cursor = 'not-allowed';
                });
            }
        });
    </script>
</body>
</html>
