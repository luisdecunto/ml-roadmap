<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 1-2 Mini-Project: Image Compression Engine - ML Roadmap</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        .markdown-body {
            line-height: 1.6;
        }
        .markdown-body h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            color: #1f2937;
            border-bottom: 3px solid #10b981;
            padding-bottom: 0.5rem;
        }
        .markdown-body h2 {
            font-size: 1.875rem;
            font-weight: 700;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: #374151;
        }
        .markdown-body h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            color: #4b5563;
        }
        .markdown-body p {
            margin-bottom: 1rem;
            color: #374151;
        }
        .markdown-body ul, .markdown-body ol {
            margin-bottom: 1rem;
            margin-left: 1.5rem;
        }
        .markdown-body li {
            margin-bottom: 0.5rem;
            color: #374151;
        }
        .markdown-body code {
            background-color: #f3f4f6;
            padding: 0.125rem 0.375rem;
            border-radius: 0.25rem;
            font-family: 'Courier New', monospace;
            font-size: 0.875rem;
            color: #dc2626;
        }
        .markdown-body pre {
            background-color: #1f2937;
            color: #f3f4f6;
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin-bottom: 1rem;
        }
        .markdown-body pre code {
            background-color: transparent;
            padding: 0;
            color: #f3f4f6;
        }
        .markdown-body a {
            color: #2563eb;
            text-decoration: underline;
        }
        .markdown-body a:hover {
            color: #1d4ed8;
        }
        .markdown-body hr {
            margin: 2rem 0;
            border: 0;
            border-top: 2px solid #e5e7eb;
        }
        .markdown-body blockquote {
            border-left: 4px solid #10b981;
            padding-left: 1rem;
            color: #6b7280;
            font-style: italic;
            margin: 1rem 0;
        }
        .markdown-body details {
            background-color: #fef3c7;
            border: 2px solid #fbbf24;
            border-radius: 0.5rem;
            padding: 1rem;
            margin: 1rem 0;
        }
        .markdown-body details[open] {
            background-color: #fef9e7;
        }
        .markdown-body summary {
            font-weight: 600;
            cursor: pointer;
            color: #d97706;
            user-select: none;
            padding: 0.5rem;
            margin: -1rem;
            margin-bottom: 1rem;
            background-color: #fde68a;
            border-radius: 0.375rem;
        }
        .markdown-body summary:hover {
            background-color: #fcd34d;
            color: #b45309;
        }
        .markdown-body details details {
            background-color: #f0fdf4;
            border: 2px solid #86efac;
        }
        .markdown-body details details summary {
            background-color: #bbf7d0;
            color: #059669;
        }
        .markdown-body details details summary:hover {
            background-color: #86efac;
            color: #047857;
        }
        .research-box {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            border-left: 4px solid #f59e0b;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.5rem;
        }
        .milestone-box {
            background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%);
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.5rem;
        }
    </style>
</head>
<body class="bg-gradient-to-br from-emerald-50 via-teal-50 to-green-50 min-h-screen">
    <div class="max-w-4xl mx-auto p-4 md:p-8">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <div class="flex items-center justify-between mb-4">
                <h1 class="text-2xl font-bold text-gray-800">üì¶ Mini-Project: Image Compression Engine</h1>
                <a href="../index.html" class="px-4 py-2 bg-emerald-600 hover:bg-emerald-700 text-white rounded-lg text-sm font-semibold">
                    ‚Üê Back to Roadmap
                </a>
            </div>
            <p class="text-gray-600">
                <strong>Modules 1-2:</strong> Linear Algebra & Matrix Calculus | <strong>Estimated Time:</strong> 20-30 hours
            </p>
        </div>

        <!-- Content Container -->
        <div class="bg-white rounded-lg shadow-lg p-6 md:p-8 markdown-body">
            <div id="guide-content"></div>
        </div>
    </div>

    <script>
        const markdown = `# Image Compression Engine using SVD

## üéØ Project Overview

**Challenge:** Build an image compression system from scratch using Singular Value Decomposition (SVD) and understand the fundamental tradeoffs between compression ratio and image quality.

**Why This Matters:** This project forces you to deeply understand:
- How matrices represent real-world data (images)
- What SVD actually *does* geometrically
- How rank reduction affects information loss
- Performance optimization and algorithm efficiency
- The mathematical foundations of JPEG-like compression

You are **NOT** building a tutorial project. You are building a **research tool** to explore compression mathematics.

---

## üìö Additional Resources

Before starting, familiarize yourself with these resources:

- [3Blue1Brown: Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) - Watch the SVD video
- [MIT OCW: Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/) - Gilbert Strang's lectures
- [Low-Rank Approximation (Wikipedia)](https://en.wikipedia.org/wiki/Low-rank_approximation) - Mathematical theory behind SVD compression
- [JPEG Compression Explained](https://www.youtube.com/watch?v=Kv1Hiv3ox8I) - To compare with your implementation

---

## üìö Learning Objectives

By completing this project, you will be able to:

1. **Explain** why SVD is effective for compression (not just "it works")
2. **Design** your own compression algorithm with tunable parameters
3. **Analyze** the relationship between rank, compression ratio, and quality
4. **Compare** your approach with real-world compression (JPEG, PNG)
5. **Optimize** matrix operations for performance
6. **Visualize** singular values and understand their meaning
7. **Implement** gradient-based optimization for automatic rank selection

---

## üî¨ Problem Statement

### Core Challenge

Design and implement an image compression system that:

1. **Takes as input:** Any color image (RGB)
2. **Compresses using:** SVD-based dimensionality reduction
3. **Produces:** Compressed representation with controllable quality
4. **Can reconstruct:** Decompressed image from compressed data
5. **Provides metrics:** Compression ratio, quality (PSNR, SSIM), storage savings

### Technical Constraints

- Must implement SVD yourself OR use NumPy's SVD with full understanding
- Must handle color images (think: how do you apply SVD to RGB?)
- Must achieve at least 10x compression while maintaining recognizable images
- Must run efficiently on 1920x1080 images (< 5 seconds for compression)
- Must provide interactive visualization of singular value spectrum

---

## ü§î Research Questions

These questions should guide your design. **Answer them before coding:**

### Fundamental Questions

1. **What does each singular value represent?**
   - Why do the first few singular values contain most information?
   - Can you visualize what each singular vector captures?

2. **How should you handle color images?**
   - Apply SVD to each channel separately?
   - Convert to different color space first (YCbCr, LAB)?
   - What are the tradeoffs?

3. **How do you choose the rank k?**
   - Fixed k for all images?
   - Adaptive based on image complexity?
   - Energy threshold (e.g., retain 95% of energy)?
   - Can you use gradient descent to find optimal k?

4. **How do you measure quality?**
   - Visual quality vs mathematical metrics
   - PSNR (Peak Signal-to-Noise Ratio)
   - SSIM (Structural Similarity Index)
   - Which metric best reflects human perception?

<details>
<summary>üí° Stuck? Click for implementation hints on these fundamentals</summary>

### Understanding Singular Values

**What they represent:**
- Each singular value œÉ·µ¢ represents the "importance" or "energy" of the i-th component
- Larger œÉ·µ¢ = more information captured by that component
- The first few components typically capture overall structure (low-frequency)
- Later components capture fine details (high-frequency)

**Why they work for compression:**
\`\`\`python
# Visualize singular value spectrum
U, sigma, Vt = np.linalg.svd(image, full_matrices=False)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.semilogy(sigma, 'b-', linewidth=2)
plt.xlabel('Component index')
plt.ylabel('Singular value (log scale)')
plt.title('Singular Value Spectrum')
plt.grid(True)

plt.subplot(1, 2, 2)
energy = np.cumsum(sigma**2) / np.sum(sigma**2) * 100
plt.plot(energy, 'g-', linewidth=2)
plt.xlabel('Number of components k')
plt.ylabel('Energy retained (%)')
plt.axhline(95, color='r', linestyle='--', label='95% threshold')
plt.legend()
plt.grid(True)
plt.show()
\`\`\`

**Why this works:** Singular values typically decay rapidly - first 10-50 components often capture 95%+ of energy.

---

### Color Image Handling Options

**Option A: Independent RGB channels**
\`\`\`python
def compress_rgb_independent(img_rgb, k):
    compressed = []
    for c in range(3):
        channel = img_rgb[:, :, c]
        U, sigma, Vt = np.linalg.svd(channel, full_matrices=False)
        compressed.append({
            'U_k': U[:, :k],
            'sigma_k': sigma[:k],
            'Vt_k': Vt[:k, :]
        })
    return compressed
\`\`\`
**Why:** Simple, preserves color balance. Same k for all channels.

**Option B: YCbCr color space**
\`\`\`python
def rgb_to_ycbcr(img_rgb):
    R, G, B = img_rgb[:,:,0], img_rgb[:,:,1], img_rgb[:,:,2]
    Y  = 0.299*R + 0.587*G + 0.114*B
    Cb = -0.169*R - 0.331*G + 0.5*B + 128
    Cr = 0.5*R - 0.419*G - 0.081*B + 128
    return np.stack([Y, Cb, Cr], axis=2)

def compress_ycbcr(img_rgb, k_luma, k_chroma):
    ycbcr = rgb_to_ycbcr(img_rgb)
    # Compress Y with k_luma, Cb/Cr with k_chroma (smaller)
    # ...
\`\`\`
**Why:** Human vision is more sensitive to brightness (Y) than color (Cb/Cr). Can compress color channels more aggressively.

**Your task:** Implement both and compare!

---

### Rank Selection Strategies

**Strategy 1: Energy threshold**
\`\`\`python
def select_k_by_energy(sigma, threshold=0.95):
    total_energy = np.sum(sigma ** 2)
    cumulative_energy = np.cumsum(sigma ** 2)
    k = np.searchsorted(cumulative_energy, threshold * total_energy) + 1
    return k
\`\`\`
**Why:** Keeps k that retains X% of total energy. Adapts to image complexity.

**Strategy 2: Target PSNR**
\`\`\`python
def select_k_by_psnr(img, target_psnr, U, sigma, Vt):
    # Binary search for smallest k achieving target PSNR
    k_min, k_max = 1, len(sigma)
    while k_min <= k_max:
        k = (k_min + k_max) // 2
        reconstructed = U[:, :k] @ np.diag(sigma[:k]) @ Vt[:k, :]
        psnr = calculate_psnr(img, reconstructed)
        if psnr >= target_psnr:
            k_max = k - 1
        else:
            k_min = k + 1
    return k_min
\`\`\`
**Why:** Direct quality control. Find minimum k for acceptable quality.

**Strategy 3: Fixed compression ratio**
\`\`\`python
def select_k_by_ratio(shape, target_ratio):
    m, n = shape
    # Ratio = (m*n) / (m*k + k + k*n)
    k = int((m * n) / (target_ratio * (m + n + 1)))
    return max(1, min(k, min(m, n)))
\`\`\`
**Why:** Predictable storage size. Good for bandwidth-limited scenarios.

**Your task:** Which works best for different types of images?

---

### Quality Metrics

**PSNR (Peak Signal-to-Noise Ratio)**
\`\`\`python
def calculate_psnr(original, reconstructed):
    mse = np.mean((original - reconstructed) ** 2)
    if mse == 0:
        return float('inf')
    max_value = 255.0  # or 1.0 if normalized
    psnr = 20 * np.log10(max_value / np.sqrt(mse))
    return psnr
\`\`\`
**Why:** Standard metric. > 40 dB = excellent, 30-40 = good, 20-30 = acceptable.

**Compression Ratio**
\`\`\`python
def calculate_compression_ratio(original_shape, k, num_channels=3):
    m, n = original_shape[:2]
    original_size = m * n * num_channels
    # Compressed: U_k (m√ók) + sigma_k (k) + Vt_k (k√ón) per channel
    compressed_size = num_channels * (m*k + k + k*n)
    return original_size / compressed_size
\`\`\`
**Why:** Shows how much space you save. 10x = 90% storage reduction.

</details>

### Advanced Questions

5. **Can you beat naive SVD compression?**
   - Block-based SVD (like JPEG)?
   - Different ranks for different regions?
   - Combine with other techniques (quantization, entropy coding)?

6. **What's the optimal image representation?**
   - Raw pixel values?
   - Frequency domain (DCT)?
   - Wavelet transform?

7. **How does this compare to JPEG?**
   - When does SVD win?
   - When does JPEG win?
   - Can you combine both approaches?

<details>
<summary>üí° Stuck? Click for hints on advanced techniques</summary>

### Block-based SVD

**Why it might work better:**
- Different image regions have different complexity
- Can use different k for each block
- Reduces artifacts (less "global" blur)

\`\`\`python
def compress_block_svd(image, block_size=16, k=10):
    h, w = image.shape
    compressed_blocks = []

    for i in range(0, h, block_size):
        for j in range(0, w, block_size):
            block = image[i:i+block_size, j:j+block_size]
            U, sigma, Vt = np.linalg.svd(block, full_matrices=False)
            compressed_blocks.append({
                'U_k': U[:, :k],
                'sigma_k': sigma[:k],
                'Vt_k': Vt[:k, :],
                'position': (i, j)
            })

    return compressed_blocks
\`\`\`

**Tradeoff:** Block artifacts vs global blur. Experiment!

---

### Comparing with JPEG

\`\`\`python
from PIL import Image

def compare_with_jpeg(img_array, target_size):
    # Save with different JPEG qualities
    for quality in range(10, 100, 10):
        img_pil = Image.fromarray(img_array)
        img_pil.save('temp.jpg', quality=quality)

        jpeg_size = os.path.getsize('temp.jpg')
        jpeg_img = np.array(Image.open('temp.jpg'))
        jpeg_psnr = calculate_psnr(img_array, jpeg_img)

        print(f"JPEG Q={quality}: {jpeg_size} bytes, PSNR={jpeg_psnr:.2f} dB")
\`\`\`

**Compare:**
- Storage size at same PSNR
- PSNR at same storage size
- Visual quality (look at artifacts)

**Observation:** JPEG usually wins for photos (it's optimized for that), but SVD is simpler and more general.

</details>

---

## üìã Requirements & Specifications

### Phase 1: Basic SVD Compressor (Required)

**Functionality:**
- Load image, convert to grayscale
- Compute SVD: A = UŒ£V^T
- Compress by keeping top k singular values
- Reconstruct: A_k = U_k Œ£_k V_k^T
- Display original vs compressed side-by-side
- Report compression ratio and PSNR

**Deliverables:**
- \`compress_image(img, k)\` function
- \`decompress_image(compressed_data)\` function
- Visualization of singular value decay
- Comparison plot: k vs PSNR vs compression ratio

<details>
<summary>üí° Stuck on implementation? Click for code skeleton</summary>

### Complete Phase 1 Implementation

\`\`\`python
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

def load_grayscale_image(filepath):
    """Load and normalize grayscale image."""
    img = Image.open(filepath).convert('L')
    img_array = np.array(img, dtype=float)
    # Normalize to [0, 1]
    img_normalized = img_array / 255.0
    return img_normalized

def compress_grayscale(img, k):
    """
    Compress grayscale image using SVD.

    Returns: dict with U_k, sigma_k, Vt_k, and metadata
    """
    # Compute SVD
    U, sigma, Vt = np.linalg.svd(img, full_matrices=False)

    # Keep only top k components
    compressed = {
        'U_k': U[:, :k],
        'sigma_k': sigma[:k],
        'Vt_k': Vt[:k, :],
        'k': k,
        'shape': img.shape,
        'full_sigma': sigma  # Keep for analysis
    }

    return compressed

def decompress_grayscale(compressed):
    """Reconstruct image from compressed representation."""
    U_k = compressed['U_k']
    sigma_k = compressed['sigma_k']
    Vt_k = compressed['Vt_k']

    # Reconstruct: A_k = U_k @ diag(sigma_k) @ Vt_k
    reconstructed = U_k @ np.diag(sigma_k) @ Vt_k

    # Clip to valid range
    reconstructed = np.clip(reconstructed, 0, 1)

    return reconstructed

def calculate_psnr(original, reconstructed):
    """Calculate Peak Signal-to-Noise Ratio."""
    mse = np.mean((original - reconstructed) ** 2)
    if mse == 0:
        return float('inf')
    max_value = 1.0  # Since normalized to [0, 1]
    psnr = 20 * np.log10(max_value / np.sqrt(mse))
    return psnr

def calculate_compression_ratio(original_shape, compressed):
    """Calculate compression ratio."""
    m, n = original_shape
    original_size = m * n

    k = compressed['k']
    compressed_size = m*k + k + k*n  # U_k + sigma_k + Vt_k

    return original_size / compressed_size

def visualize_compression(original, reconstructed, compressed):
    """Create comprehensive visualization."""
    k = compressed['k']
    sigma = compressed['full_sigma']

    fig = plt.figure(figsize=(16, 10))

    # Row 1: Images
    ax1 = plt.subplot(2, 3, 1)
    ax1.imshow(original, cmap='gray', vmin=0, vmax=1)
    ax1.set_title('Original', fontsize=14)
    ax1.axis('off')

    ax2 = plt.subplot(2, 3, 2)
    ax2.imshow(reconstructed, cmap='gray', vmin=0, vmax=1)
    psnr = calculate_psnr(original, reconstructed)
    ratio = calculate_compression_ratio(original.shape, compressed)
    ax2.set_title(f'Compressed (k={k})\\nPSNR: {psnr:.2f} dB\\nRatio: {ratio:.2f}x', fontsize=14)
    ax2.axis('off')

    ax3 = plt.subplot(2, 3, 3)
    diff = np.abs(original - reconstructed)
    ax3.imshow(diff * 10, cmap='hot', vmin=0, vmax=1)
    ax3.set_title('Difference (10x amplified)', fontsize=14)
    ax3.axis('off')

    # Row 2: Analysis
    ax4 = plt.subplot(2, 3, 4)
    ax4.semilogy(sigma, 'b-', linewidth=2)
    ax4.axvline(k, color='r', linestyle='--', linewidth=2, label=f'k={k}')
    ax4.set_xlabel('Component index i', fontsize=12)
    ax4.set_ylabel('Singular value œÉ·µ¢ (log)', fontsize=12)
    ax4.set_title('Singular Value Spectrum', fontsize=14)
    ax4.grid(True, alpha=0.3)
    ax4.legend()

    ax5 = plt.subplot(2, 3, 5)
    energy = np.cumsum(sigma**2) / np.sum(sigma**2) * 100
    ax5.plot(energy, 'g-', linewidth=2)
    ax5.axvline(k, color='r', linestyle='--', linewidth=2, label=f'k={k}')
    ax5.axhline(95, color='orange', linestyle=':', linewidth=2, label='95% energy')
    ax5.set_xlabel('Number of components k', fontsize=12)
    ax5.set_ylabel('Cumulative energy (%)', fontsize=12)
    ax5.set_title('Energy Retention', fontsize=14)
    ax5.grid(True, alpha=0.3)
    ax5.legend()

    ax6 = plt.subplot(2, 3, 6)
    metrics_text = (
        f"Rank k: {k}\\n"
        f"PSNR: {psnr:.2f} dB\\n"
        f"Compression: {ratio:.2f}x\\n"
        f"Energy retained: {energy[k-1]:.1f}%\\n"
        f"Original: {original.shape[0]}√ó{original.shape[1]}\\n"
        f"Storage: {compressed_size/1000:.1f} KB ‚Üí {original_size/1000:.1f} KB"
    )
    ax6.text(0.5, 0.5, metrics_text, ha='center', va='center',
             fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    ax6.axis('off')
    ax6.set_title('Metrics Summary', fontsize=14)

    plt.tight_layout()
    return fig

# Example usage
if __name__ == "__main__":
    # Load image
    img = load_grayscale_image('test_image.jpg')
    print(f"Image shape: {img.shape}")

    # Try different k values
    k_values = [5, 10, 20, 50, 100]

    for k in k_values:
        # Compress
        compressed = compress_grayscale(img, k)

        # Decompress
        reconstructed = decompress_grayscale(compressed)

        # Metrics
        psnr = calculate_psnr(img, reconstructed)
        ratio = calculate_compression_ratio(img.shape, compressed)

        print(f"k={k:3d}: PSNR={psnr:6.2f} dB, Ratio={ratio:6.2f}x")

    # Visualize one case
    compressed_50 = compress_grayscale(img, k=50)
    reconstructed_50 = decompress_grayscale(compressed_50)
    fig = visualize_compression(img, reconstructed_50, compressed_50)
    plt.savefig('compression_result.png', dpi=150, bbox_inches='tight')
    plt.show()
\`\`\`

**Why each piece:**
- **Normalization [0,1]:** Better numerical stability for SVD
- **full_matrices=False:** Compact SVD, saves memory
- **Clipping:** Ensures reconstructed values stay valid
- **Log scale plot:** Singular values decay exponentially
- **Energy curve:** Shows diminishing returns of adding more components

</details>

### Phase 2: Color Image Support (Required)

**Research Challenge:**
How do you extend SVD to RGB images? Multiple approaches possible:

- **Approach A:** Apply SVD to each channel independently
- **Approach B:** Convert to YCbCr, compress Y more than CbCr
- **Approach C:** Reshape to 2D matrix differently

**You must:**
- Try at least 2 different approaches
- Compare their performance
- Justify your choice with data

<details>
<summary>üí° Stuck? Click for color handling implementation</summary>

### Color Image Handling - Complete Implementation

\`\`\`python
def load_color_image(filepath):
    """Load and normalize color image."""
    img = Image.open(filepath)
    img_array = np.array(img, dtype=float)
    img_normalized = img_array / 255.0
    return img_normalized

# Approach A: Independent RGB
def compress_rgb_independent(img_rgb, k):
    """Compress each RGB channel independently."""
    compressed_channels = []

    for c in range(3):
        channel = img_rgb[:, :, c]
        U, sigma, Vt = np.linalg.svd(channel, full_matrices=False)
        compressed_channels.append({
            'U_k': U[:, :k],
            'sigma_k': sigma[:k],
            'Vt_k': Vt[:k, :],
            'full_sigma': sigma
        })

    return {'method': 'rgb', 'channels': compressed_channels, 'k': k}

def decompress_rgb_independent(compressed):
    """Reconstruct RGB from compressed channels."""
    reconstructed_channels = []

    for ch in compressed['channels']:
        U_k = ch['U_k']
        sigma_k = ch['sigma_k']
        Vt_k = ch['Vt_k']
        reconstructed = U_k @ np.diag(sigma_k) @ Vt_k
        reconstructed_channels.append(np.clip(reconstructed, 0, 1))

    return np.stack(reconstructed_channels, axis=2)

# Approach B: YCbCr
def rgb_to_ycbcr(img_rgb):
    """Convert RGB to YCbCr color space."""
    R, G, B = img_rgb[:,:,0], img_rgb[:,:,1], img_rgb[:,:,2]

    Y  = 0.299 * R + 0.587 * G + 0.114 * B
    Cb = -0.169 * R - 0.331 * G + 0.5 * B + 0.5
    Cr = 0.5 * R - 0.419 * G - 0.081 * B + 0.5

    return np.stack([Y, Cb, Cr], axis=2)

def ycbcr_to_rgb(img_ycbcr):
    """Convert YCbCr back to RGB."""
    Y, Cb, Cr = img_ycbcr[:,:,0], img_ycbcr[:,:,1], img_ycbcr[:,:,2]

    Cb = Cb - 0.5
    Cr = Cr - 0.5

    R = Y + 1.402 * Cr
    G = Y - 0.344 * Cb - 0.714 * Cr
    B = Y + 1.772 * Cb

    return np.clip(np.stack([R, G, B], axis=2), 0, 1)

def compress_rgb_ycbcr(img_rgb, k_luma, k_chroma):
    """Compress using YCbCr with different k for luminance vs chrominance."""
    img_ycbcr = rgb_to_ycbcr(img_rgb)

    compressed_channels = []
    k_values = [k_luma, k_chroma, k_chroma]

    for c, k in enumerate(k_values):
        channel = img_ycbcr[:, :, c]
        U, sigma, Vt = np.linalg.svd(channel, full_matrices=False)
        compressed_channels.append({
            'U_k': U[:, :k],
            'sigma_k': sigma[:k],
            'Vt_k': Vt[:k, :],
            'full_sigma': sigma,
            'k': k
        })

    return {'method': 'ycbcr', 'channels': compressed_channels, 'k_luma': k_luma, 'k_chroma': k_chroma}

def decompress_rgb_ycbcr(compressed):
    """Reconstruct RGB from compressed YCbCr."""
    ycbcr_channels = []

    for ch in compressed['channels']:
        U_k = ch['U_k']
        sigma_k = ch['sigma_k']
        Vt_k = ch['Vt_k']
        reconstructed = U_k @ np.diag(sigma_k) @ Vt_k
        ycbcr_channels.append(np.clip(reconstructed, 0, 1))

    img_ycbcr = np.stack(ycbcr_channels, axis=2)
    return ycbcr_to_rgb(img_ycbcr)

def compare_color_approaches(img_rgb):
    """Compare RGB vs YCbCr approaches."""
    print("\\n" + "="*60)
    print("Color Compression Comparison")
    print("="*60)

    # Approach A: RGB with k=50 for all
    compressed_rgb = compress_rgb_independent(img_rgb, k=50)
    reconstructed_rgb = decompress_rgb_independent(compressed_rgb)
    psnr_rgb = calculate_psnr(img_rgb, reconstructed_rgb)

    # Calculate storage for RGB
    m, n = img_rgb.shape[:2]
    k = 50
    storage_rgb = 3 * (m*k + k + k*n)
    ratio_rgb = (m * n * 3) / storage_rgb

    print(f"\\nApproach A: RGB Independent (k=50 all channels)")
    print(f"  PSNR: {psnr_rgb:.2f} dB")
    print(f"  Compression ratio: {ratio_rgb:.2f}x")
    print(f"  Storage: {storage_rgb} values")

    # Approach B: YCbCr with k_Y=50, k_CbCr=25
    compressed_ycbcr = compress_rgb_ycbcr(img_rgb, k_luma=50, k_chroma=25)
    reconstructed_ycbcr = decompress_rgb_ycbcr(compressed_ycbcr)
    psnr_ycbcr = calculate_psnr(img_rgb, reconstructed_ycbcr)

    # Calculate storage for YCbCr
    storage_ycbcr = (m*50 + 50 + 50*n) + 2 * (m*25 + 25 + 25*n)
    ratio_ycbcr = (m * n * 3) / storage_ycbcr

    print(f"\\nApproach B: YCbCr (k_Y=50, k_CbCr=25)")
    print(f"  PSNR: {psnr_ycbcr:.2f} dB")
    print(f"  Compression ratio: {ratio_ycbcr:.2f}x")
    print(f"  Storage: {storage_ycbcr} values")

    print(f"\\nResult:")
    if psnr_ycbcr > psnr_rgb and ratio_ycbcr > ratio_rgb:
        print(f"  ‚úÖ YCbCr wins! Better quality AND compression")
    elif psnr_ycbcr > psnr_rgb:
        print(f"  ‚öñÔ∏è  YCbCr: better quality (+{psnr_ycbcr-psnr_rgb:.2f} dB)")
    elif ratio_ycbcr > ratio_rgb:
        print(f"  ‚öñÔ∏è  YCbCr: better compression (+{ratio_ycbcr-ratio_rgb:.2f}x)")
    else:
        print(f"  ‚öñÔ∏è  RGB might be simpler for this case")

    # Visualize
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    axes[0, 0].imshow(img_rgb)
    axes[0, 0].set_title('Original', fontsize=14)
    axes[0, 0].axis('off')

    axes[0, 1].imshow(reconstructed_rgb)
    axes[0, 1].set_title(f'RGB Method\\nPSNR: {psnr_rgb:.2f} dB\\nRatio: {ratio_rgb:.2f}x', fontsize=14)
    axes[0, 1].axis('off')

    axes[0, 2].imshow(reconstructed_ycbcr)
    axes[0, 2].set_title(f'YCbCr Method\\nPSNR: {psnr_ycbcr:.2f} dB\\nRatio: {ratio_ycbcr:.2f}x', fontsize=14)
    axes[0, 2].axis('off')

    # Difference maps
    diff_rgb = np.abs(img_rgb - reconstructed_rgb)
    diff_ycbcr = np.abs(img_rgb - reconstructed_ycbcr)

    axes[1, 0].axis('off')

    axes[1, 1].imshow(np.mean(diff_rgb, axis=2) * 10, cmap='hot', vmin=0, vmax=1)
    axes[1, 1].set_title('RGB Error (10x)', fontsize=14)
    axes[1, 1].axis('off')

    axes[1, 2].imshow(np.mean(diff_ycbcr, axis=2) * 10, cmap='hot', vmin=0, vmax=1)
    axes[1, 2].set_title('YCbCr Error (10x)', fontsize=14)
    axes[1, 2].axis('off')

    plt.tight_layout()
    return fig

# Usage
img_color = load_color_image('test_color.jpg')
fig = compare_color_approaches(img_color)
plt.savefig('color_comparison.png', dpi=150, bbox_inches='tight')
plt.show()
\`\`\`

**Why YCbCr often wins:**
- Human vision: more sensitive to luminance (Y) than chrominance (Cb, Cr)
- Can compress Cb/Cr more aggressively without visible quality loss
- Same principle JPEG uses

**Your task:** Test on multiple images and decide which approach you prefer!

</details>

### Phase 3: Adaptive Rank Selection (Required)

**Challenge:** Don't hardcode k - find it automatically.

**Options to explore:**
1. **Energy threshold:** Keep k values that capture 95% of total energy
2. **Quality constraint:** Find smallest k that achieves target PSNR
3. **Hybrid:** Balance compression ratio and quality using weighted objective

**Deliverable:**
- \`auto_select_rank(image, strategy, params)\` function
- Comparison of different strategies
- Justify which strategy works best and why

<details>
<summary>üí° Stuck? Click for adaptive rank selection implementation</summary>

### Adaptive Rank Selection - All Strategies

\`\`\`python
def select_k_by_energy(sigma, threshold=0.95):
    """
    Select k that retains at least threshold% of total energy.

    Energy = sum of squared singular values.
    """
    total_energy = np.sum(sigma ** 2)
    cumulative_energy = np.cumsum(sigma ** 2)

    # Find smallest k where energy >= threshold
    k = np.searchsorted(cumulative_energy, threshold * total_energy) + 1

    # Make sure k is valid
    k = min(k, len(sigma))

    return k

def select_k_by_psnr(img, target_psnr, U, sigma, Vt):
    """
    Binary search for smallest k achieving target PSNR.
    """
    k_min, k_max = 1, len(sigma)
    best_k = k_max

    while k_min <= k_max:
        k = (k_min + k_max) // 2

        # Reconstruct with this k
        reconstructed = U[:, :k] @ np.diag(sigma[:k]) @ Vt[:k, :]
        reconstructed = np.clip(reconstructed, 0, 1)

        # Calculate PSNR
        psnr = calculate_psnr(img, reconstructed)

        if psnr >= target_psnr:
            best_k = k
            k_max = k - 1  # Try smaller k
        else:
            k_min = k + 1  # Need larger k

    return best_k

def select_k_by_ratio(shape, target_ratio):
    """
    Select k to achieve target compression ratio.

    For grayscale: ratio = (m*n) / (m*k + k + k*n)
    Solving for k: k = (m*n) / (ratio * (m + n + 1))
    """
    m, n = shape[:2]
    k = int((m * n) / (target_ratio * (m + n + 1)))

    # Clamp to valid range
    k = max(1, min(k, min(m, n)))

    return k

def compare_selection_strategies(images_dict):
    """
    Compare all three strategies on multiple images.

    images_dict: {'name': img_array}
    """
    strategies = {
        'Energy 90%': lambda img, U, s, Vt: select_k_by_energy(s, 0.90),
        'Energy 95%': lambda img, U, s, Vt: select_k_by_energy(s, 0.95),
        'Energy 99%': lambda img, U, s, Vt: select_k_by_energy(s, 0.99),
        'PSNR 30dB': lambda img, U, s, Vt: select_k_by_psnr(img, 30.0, U, s, Vt),
        'PSNR 35dB': lambda img, U, s, Vt: select_k_by_psnr(img, 35.0, U, s, Vt),
        'PSNR 40dB': lambda img, U, s, Vt: select_k_by_psnr(img, 40.0, U, s, Vt),
        'Ratio 5x': lambda img, U, s, Vt: select_k_by_ratio(img.shape, 5.0),
        'Ratio 10x': lambda img, U, s, Vt: select_k_by_ratio(img.shape, 10.0),
        'Ratio 20x': lambda img, U, s, Vt: select_k_by_ratio(img.shape, 20.0),
    }

    results = []

    for img_name, img in images_dict.items():
        # Compute SVD once
        U, sigma, Vt = np.linalg.svd(img, full_matrices=False)

        for strategy_name, strategy_func in strategies.items():
            # Select k using strategy
            k = strategy_func(img, U, sigma, Vt)

            # Reconstruct
            reconstructed = U[:, :k] @ np.diag(sigma[:k]) @ Vt[:k, :]
            reconstructed = np.clip(reconstructed, 0, 1)

            # Metrics
            psnr = calculate_psnr(img, reconstructed)
            ratio = (img.shape[0] * img.shape[1]) / (img.shape[0]*k + k + k*img.shape[1])

            results.append({
                'Image': img_name,
                'Strategy': strategy_name,
                'k': k,
                'PSNR (dB)': psnr,
                'Compression Ratio': ratio
            })

    import pandas as pd
    df = pd.DataFrame(results)

    print("\\n" + "="*80)
    print("Adaptive Rank Selection Strategy Comparison")
    print("="*80)
    print(df.to_string(index=False))

    # Visualize
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # Plot 1: k values by strategy
    pivot1 = df.pivot(index='Strategy', columns='Image', values='k')
    pivot1.plot(kind='bar', ax=axes[0], width=0.8)
    axes[0].set_title('Selected k by Strategy', fontsize=14)
    axes[0].set_ylabel('Rank k', fontsize=12)
    axes[0].legend(title='Image')
    axes[0].grid(True, alpha=0.3)

    # Plot 2: PSNR by strategy
    pivot2 = df.pivot(index='Strategy', columns='Image', values='PSNR (dB)')
    pivot2.plot(kind='bar', ax=axes[1], width=0.8)
    axes[1].set_title('Resulting PSNR', fontsize=14)
    axes[1].set_ylabel('PSNR (dB)', fontsize=12)
    axes[1].axhline(30, color='orange', linestyle='--', alpha=0.5, label='30 dB threshold')
    axes[1].axhline(40, color='green', linestyle='--', alpha=0.5, label='40 dB threshold')
    axes[1].legend(title='Image')
    axes[1].grid(True, alpha=0.3)

    # Plot 3: Compression ratio by strategy
    pivot3 = df.pivot(index='Strategy', columns='Image', values='Compression Ratio')
    pivot3.plot(kind='bar', ax=axes[2], width=0.8)
    axes[2].set_title('Compression Ratio', fontsize=14)
    axes[2].set_ylabel('Ratio', fontsize=12)
    axes[2].legend(title='Image')
    axes[2].grid(True, alpha=0.3)

    plt.tight_layout()
    return df, fig

# Test on different image types
test_images = {
    'Smooth': create_smooth_gradient(512, 512),
    'Photo': load_grayscale_image('photo.jpg'),
    'Texture': load_grayscale_image('texture.jpg'),
    'Text': load_grayscale_image('text.jpg')
}

df_results, fig = compare_selection_strategies(test_images)
plt.savefig('strategy_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# Analysis
print("\\n" + "="*80)
print("Analysis & Recommendations")
print("="*80)
print("\\n1. Energy-based strategies:")
print("   - Adapt to image complexity automatically")
print("   - Simple images need fewer components")
print("   - Complex images get more components")
print("   - RECOMMENDATION: Use 95% threshold as default")
print("\\n2. PSNR-based strategies:")
print("   - Predictable quality")
print("   - Good for applications with quality requirements")
print("   - RECOMMENDATION: Use PSNR 35dB for 'good quality'")
print("\\n3. Ratio-based strategies:")
print("   - Predictable storage size")
print("   - Ignores image content")
print("   - RECOMMENDATION: Use for bandwidth-limited scenarios")
\`\`\`

**Helper function for testing:**
\`\`\`python
def create_smooth_gradient(h, w):
    """Create smooth gradient test image."""
    x = np.linspace(0, 1, w)
    y = np.linspace(0, 1, h)
    X, Y = np.meshgrid(x, y)
    return X * 0.5 + Y * 0.5
\`\`\`

**Your task:**
1. Run comparison on your own test images
2. Observe which strategy is most consistent
3. Pick one strategy and justify your choice
4. Document the tradeoffs you discovered

</details>

### Phase 4: Performance Optimization (Optional)

**Challenge:** Make it fast.

**Optimization opportunities:**
- Use truncated SVD (only compute top k components)
- Implement block-based compression
- Parallelize channel processing
- Use efficient storage format

**Benchmark target:**
- Compress 1920x1080 image in < 5 seconds
- Memory efficient (don't store full matrices)

### Phase 5: Advanced Extensions (Optional)

Pick one or more:

1. **Block-based SVD:** Divide image into blocks, compress each separately
2. **Region-adaptive compression:** Use different k for different regions
3. **Progressive compression:** Allow gradual quality improvement
4. **Combine with JPEG:** Use SVD in frequency domain
5. **Video compression:** Extend to video frames

---

## üéØ Milestones & Validation

<div class="milestone-box">

### Milestone 1: Grayscale Compression Working

**Success Criteria:**
- Can compress/decompress grayscale images
- Visually reasonable results at k=50 for 512x512 image
- PSNR > 30 dB for k=50
- Compression ratio > 5x

**Validation:**
- Test on multiple images (faces, landscapes, text)
- Does it work better on some types of images? Why?

</div>

<div class="milestone-box">

### Milestone 2: Color Images Supported

**Success Criteria:**
- Color images compress/decompress correctly
- No color distortion or artifacts
- Reasonable compression ratios

**Validation:**
- Compare your approaches quantitatively
- Which color space works best? Why?
- Show visual comparison of different approaches

</div>

<div class="milestone-box">

### Milestone 3: Adaptive Rank Selection Working

**Success Criteria:**
- System automatically chooses k
- Different k for different images (based on complexity)
- Meets quality targets consistently

**Validation:**
- Test on diverse image set
- Show k vs image complexity relationship
- Prove your strategy is better than fixed k

</div>

<div class="milestone-box">

### Milestone 4: Complete Analysis & Visualization

**Success Criteria:**
- Interactive tool to explore compression tradeoffs
- Clear visualizations of singular value spectrum
- Comprehensive comparison with JPEG

**Validation:**
- Can explain SVD compression to non-technical person
- Dashboard shows all relevant metrics
- Insights documented in final report

</div>

---

## üí° Hints & Resources

<div class="research-box">

### Hint 1: Understanding SVD Geometrically

Before implementing, understand what SVD does:
- U: Orthonormal basis for column space (image basis)
- Œ£: Scaling factors (importance of each basis)
- V^T: Orthonormal basis for row space

**Visualization idea:** Plot first 10 singular vectors as images - what do they look like?

</div>

<div class="research-box">

### Hint 2: Compression Ratio Calculation

Compression ratio = Original size / Compressed size

**Original:** m √ó n matrix = m ¬∑ n values

**Compressed:**
- U_k: m √ó k
- Œ£_k: k values
- V_k^T: k √ó n
- Total: m ¬∑ k + k + k ¬∑ n = k(m + n + 1)

Ratio: (m ¬∑ n) / (k(m + n + 1))

</div>

<div class="research-box">

### Hint 3: Quality Metrics

**PSNR (Peak Signal-to-Noise Ratio):**
PSNR = 10 log‚ÇÅ‚ÇÄ(MAX¬≤ / MSE)

Where MSE = Mean Squared Error between original and compressed

**Rule of thumb:**
- PSNR > 40 dB: Excellent quality
- PSNR 30-40 dB: Good quality
- PSNR 20-30 dB: Acceptable
- PSNR < 20 dB: Poor quality

</div>

<div class="research-box">

### Hint 4: Color Space Considerations

**RGB:** Simple but not optimal
- Human eye more sensitive to luminance than chrominance
- Equal compression on all channels wastes opportunity

**YCbCr:** Better for compression
- Y: Luminance (keep more detail)
- Cb, Cr: Chrominance (can compress more)
- JPEG uses this approach

**Conversion:** Look up RGB ‚Üî YCbCr formulas

</div>

---

## üìä Suggested Experiments

Run these experiments to build intuition:

### Experiment 1: Singular Value Decay

**Question:** How quickly do singular values decay?

**Procedure:**
1. Load test image
2. Compute SVD
3. Plot singular values œÉ·µ¢ (log scale)
4. Plot cumulative energy

**What to observe:**
- How many singular values to capture 90% energy?
- Does this differ for different image types?

### Experiment 2: Rank vs Quality

**Question:** How does quality degrade with compression?

**Procedure:**
1. Vary k from 1 to full rank
2. For each k, compute PSNR and compression ratio
3. Plot Pareto frontier: compression ratio vs PSNR

**What to observe:**
- Diminishing returns (elbow point)
- Which k values give best tradeoff?

### Experiment 3: Image Type Comparison

**Question:** Does SVD work equally well on all images?

**Test images:**
- Smooth gradient
- Detailed texture
- Sharp edges
- Face photo
- Text/line art

**What to observe:**
- Which images compress best?
- Why? (Think: rank = complexity)

### Experiment 4: Block-based vs Full Image

**Question:** Is block-based compression better?

**Procedure:**
1. Full image SVD with rank k
2. Divide into 8x8 blocks, SVD each with rank k'
3. Compare quality and compression

**What to observe:**
- Block artifacts vs blur
- Compression ratio differences
- When is each approach better?

---

## üé® Visualization Ideas

Build an **interactive dashboard** showing:

1. **Side-by-side comparison**
   - Original | Compressed | Difference (amplified)
   - Zoom capability to see details

2. **Singular value spectrum**
   - Bar plot of œÉ·µ¢
   - Cumulative energy curve
   - Slider to select k and see effect

3. **Compression tradeoff plot**
   - X-axis: Compression ratio
   - Y-axis: PSNR
   - Points for different k values
   - Mark optimal operating points

4. **Basis visualization**
   - Show first 16 singular vectors as images
   - See what patterns they capture

5. **Comparison matrix**
   - Multiple images, multiple k values
   - Grid showing all combinations

---

## üìù Documentation Requirements

Your project should include:

### 1. Technical Report

**Sections:**
- **Introduction:** Problem statement and approach
- **Theory:** SVD mathematics and why it works for compression
- **Methodology:** Design decisions and tradeoffs
- **Experiments:** Results from your experiments
- **Analysis:** Insights and discoveries
- **Comparison:** SVD vs JPEG analysis
- **Conclusion:** What you learned

### 2. Code Documentation

- Clear docstrings for all functions
- Type hints (Python 3.8+)
- Usage examples in README
- Requirements.txt with dependencies

### 3. Presentation (Optional)

Create a 5-minute presentation explaining:
- The math behind SVD compression
- Your implementation approach
- Most interesting findings
- Demo of your tool

---

## üéì Assessment Criteria

**Does your project demonstrate:**

‚úÖ **Mathematical Understanding**
- Can explain why SVD works for compression
- Understands singular values geometrically
- Can derive compression ratio formula

‚úÖ **Engineering Skills**
- Clean, modular code
- Efficient implementation
- Good software design

‚úÖ **Scientific Thinking**
- Hypothesis-driven experiments
- Data-driven decisions
- Honest analysis of limitations

‚úÖ **Communication**
- Clear visualizations
- Well-written report
- Reproducible results

---

## üöÄ Getting Started

### Week 1: Foundation
- [ ] Implement basic SVD compression for grayscale
- [ ] Understand singular value decay
- [ ] Create basic visualization

### Week 2: Color & Adaptation
- [ ] Extend to color images
- [ ] Implement adaptive rank selection
- [ ] Run comparison experiments

### Week 3: Optimization & Analysis
- [ ] Optimize performance
- [ ] Compare with JPEG
- [ ] Write comprehensive report

### Week 4 (Optional): Extensions
- [ ] Implement advanced feature
- [ ] Create polished dashboard
- [ ] Prepare presentation

---

## üéÅ Bonus Challenges

If you finish early and want to go deeper:

1. **Implement Progressive SVD**
   - Stream singular values from most to least important
   - Allow gradual quality improvement

2. **Build Web Interface**
   - Upload image in browser
   - Adjust compression slider
   - Download compressed result

3. **Compare Multiple Methods**
   - SVD vs PCA vs NMF
   - Which works best for images?

4. **Theoretical Analysis**
   - Derive optimal k formula
   - Prove compression ratio bounds
   - Analyze computational complexity

5. **Create Video Compression**
   - Extend to temporal dimension
   - Apply SVD across frames
   - Compare with modern video codecs

---

<details>
<summary>üí° Click for Complete Reference Implementation (Try on your own first!)</summary>

# Complete Reference Implementation

Below is a full working implementation combining all phases.

\`\`\`python
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os

class SVDImageCompressor:
    """
    Complete SVD-based image compression system.

    Supports:
    - Grayscale and color images
    - Multiple k selection strategies
    - RGB and YCbCr color spaces
    """

    def __init__(self, k_selection='energy', k_param=0.95, color_method='ycbcr'):
        """
        Initialize compressor.

        Args:
            k_selection: 'fixed', 'energy', 'psnr', 'ratio'
            k_param: parameter for k selection
            color_method: 'rgb' or 'ycbcr'
        """
        self.k_selection = k_selection
        self.k_param = k_param
        self.color_method = color_method

    def compress(self, img, k=None):
        """Compress image (grayscale or color)."""
        img_norm = img.astype(float) / 255.0

        if len(img.shape) == 2:
            return self._compress_grayscale(img_norm, k)
        else:
            return self._compress_color(img_norm, k)

    def decompress(self, compressed):
        """Reconstruct image from compressed representation."""
        if 'method' in compressed:
            # Color image
            if compressed['method'] == 'rgb':
                return self._decompress_rgb(compressed)
            else:
                return self._decompress_ycbcr(compressed)
        else:
            # Grayscale
            return self._decompress_grayscale(compressed)

    def _compress_grayscale(self, img, k=None):
        """Compress grayscale image."""
        U, sigma, Vt = np.linalg.svd(img, full_matrices=False)

        if k is None:
            k = self._select_k(img.shape, sigma, img, U, Vt)

        return {
            'U_k': U[:, :k],
            'sigma_k': sigma[:k],
            'Vt_k': Vt[:k, :],
            'k': k,
            'shape': img.shape,
            'full_sigma': sigma
        }

    def _decompress_grayscale(self, compressed):
        """Reconstruct grayscale image."""
        reconstructed = (
            compressed['U_k'] @
            np.diag(compressed['sigma_k']) @
            compressed['Vt_k']
        )
        reconstructed = np.clip(reconstructed * 255, 0, 255)
        return reconstructed.astype(np.uint8)

    def _compress_color(self, img, k=None):
        """Compress color image."""
        if self.color_method == 'rgb':
            return self._compress_rgb(img, k)
        else:
            return self._compress_ycbcr(img, k)

    def _compress_rgb(self, img, k):
        """Compress RGB independently."""
        channels = []
        for c in range(3):
            channels.append(self._compress_grayscale(img[:, :, c], k))
        return {'method': 'rgb', 'channels': channels}

    def _compress_ycbcr(self, img, k):
        """Compress in YCbCr space."""
        img_ycbcr = self._rgb_to_ycbcr(img)

        k_luma = k if k is not None else None
        k_chroma = k // 2 if k is not None else None

        channels = [
            self._compress_grayscale(img_ycbcr[:, :, 0], k_luma),
            self._compress_grayscale(img_ycbcr[:, :, 1], k_chroma),
            self._compress_grayscale(img_ycbcr[:, :, 2], k_chroma)
        ]

        return {'method': 'ycbcr', 'channels': channels}

    def _decompress_rgb(self, compressed):
        """Reconstruct RGB image."""
        channels = [self._decompress_grayscale(ch) for ch in compressed['channels']]
        return np.stack(channels, axis=2)

    def _decompress_ycbcr(self, compressed):
        """Reconstruct from YCbCr."""
        ycbcr_channels = [self._decompress_grayscale(ch) for ch in compressed['channels']]
        img_ycbcr = np.stack(ycbcr_channels, axis=2)
        return self._ycbcr_to_rgb(img_ycbcr)

    def _rgb_to_ycbcr(self, img_rgb):
        """RGB to YCbCr conversion."""
        R, G, B = img_rgb[:,:,0], img_rgb[:,:,1], img_rgb[:,:,2]
        Y  = 0.299*R + 0.587*G + 0.114*B
        Cb = -0.169*R - 0.331*G + 0.5*B + 0.5
        Cr = 0.5*R - 0.419*G - 0.081*B + 0.5
        return np.stack([Y, Cb, Cr], axis=2)

    def _ycbcr_to_rgb(self, img_ycbcr):
        """YCbCr to RGB conversion."""
        img_ycbcr = img_ycbcr.astype(float) / 255.0
        Y, Cb, Cr = img_ycbcr[:,:,0], img_ycbcr[:,:,1], img_ycbcr[:,:,2]
        Cb, Cr = Cb - 0.5, Cr - 0.5

        R = Y + 1.402 * Cr
        G = Y - 0.344 * Cb - 0.714 * Cr
        B = Y + 1.772 * Cb

        rgb = np.stack([R, G, B], axis=2)
        return np.clip(rgb * 255, 0, 255).astype(np.uint8)

    def _select_k(self, shape, sigma, img, U, Vt):
        """Select k based on strategy."""
        if self.k_selection == 'fixed':
            return int(self.k_param)
        elif self.k_selection == 'energy':
            return self._select_k_energy(sigma, self.k_param)
        elif self.k_selection == 'psnr':
            return self._select_k_psnr(img, self.k_param, U, sigma, Vt)
        elif self.k_selection == 'ratio':
            return self._select_k_ratio(shape, self.k_param)

    def _select_k_energy(self, sigma, threshold):
        """Select k by energy threshold."""
        cumulative = np.cumsum(sigma**2) / np.sum(sigma**2)
        return int(np.searchsorted(cumulative, threshold) + 1)

    def _select_k_psnr(self, img, target_psnr, U, sigma, Vt):
        """Select k by target PSNR (binary search)."""
        k_min, k_max = 1, len(sigma)
        best_k = k_max

        while k_min <= k_max:
            k = (k_min + k_max) // 2
            reconstructed = U[:, :k] @ np.diag(sigma[:k]) @ Vt[:k, :]
            psnr = self.calculate_psnr(img, reconstructed)

            if psnr >= target_psnr:
                best_k = k
                k_max = k - 1
            else:
                k_min = k + 1

        return best_k

    def _select_k_ratio(self, shape, target_ratio):
        """Select k by target compression ratio."""
        m, n = shape[:2]
        k = int((m * n) / (target_ratio * (m + n + 1)))
        return max(1, min(k, min(m, n)))

    @staticmethod
    def calculate_psnr(original, reconstructed):
        """Calculate PSNR."""
        mse = np.mean((original - reconstructed) ** 2)
        if mse == 0:
            return float('inf')
        max_value = 1.0
        return 20 * np.log10(max_value / np.sqrt(mse))

    @staticmethod
    def calculate_compression_ratio(original_shape, compressed):
        """Calculate compression ratio."""
        m, n = original_shape[:2]

        if 'method' in compressed:
            # Color image
            total_size = 0
            for ch in compressed['channels']:
                k = ch['k']
                total_size += m*k + k + k*n
            original_size = m * n * 3
        else:
            # Grayscale
            k = compressed['k']
            total_size = m*k + k + k*n
            original_size = m * n

        return original_size / total_size


# Example usage
if __name__ == "__main__":
    # Test grayscale
    compressor = SVDImageCompressor(k_selection='energy', k_param=0.95)

    img = Image.open('test.jpg')
    img_array = np.array(img)

    # Compress
    compressed = compressor.compress(img_array)

    # Decompress
    reconstructed = compressor.decompress(compressed)

    # Metrics
    psnr = compressor.calculate_psnr(
        img_array.astype(float)/255,
        reconstructed.astype(float)/255
    )
    ratio = compressor.calculate_compression_ratio(img_array.shape, compressed)

    print(f"PSNR: {psnr:.2f} dB")
    print(f"Compression: {ratio:.2f}x")

    # Display
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(img_array)
    axes[0].set_title('Original')
    axes[0].axis('off')
    axes[1].imshow(reconstructed)
    axes[1].set_title(f'Compressed\\nPSNR: {psnr:.1f} dB, Ratio: {ratio:.1f}x')
    axes[1].axis('off')
    plt.tight_layout()
    plt.savefig('result.png', dpi=150)
    plt.show()
\`\`\`

This implementation includes everything: grayscale, color (RGB and YCbCr), all k selection strategies, and proper normalization/clipping.

</details>

---

## ‚úÖ Final Checklist

Before considering this project complete:

- [ ] Grayscale compression working correctly
- [ ] Color image support implemented
- [ ] Adaptive rank selection functional
- [ ] Comprehensive visualizations created
- [ ] All experiments documented
- [ ] Comparison with JPEG performed
- [ ] Code is clean and well-documented
- [ ] Technical report written
- [ ] Can explain SVD compression to others

**Most importantly:**
- [ ] You **understand** why SVD works for compression
- [ ] You **explain** the tradeoffs you discovered
- [ ] You have **intuition** for singular values and their meaning

---

Good luck! Remember: this is about **understanding**, not just getting code to run. Take your time, experiment, and build intuition. üöÄ
`;

        // Render markdown
        document.getElementById('guide-content').innerHTML = marked.parse(markdown);

        // Make checkboxes interactive and persistent
        const checkboxes = document.querySelectorAll('input[type="checkbox"]');
        const storageKey = 'project_module1_2_checklist';

        // Load saved state
        const saved = localStorage.getItem(storageKey);
        const checkedState = saved ? JSON.parse(saved) : {};

        checkboxes.forEach((checkbox, index) => {
            const checkboxId = `checkbox_${index}`;
            checkbox.id = checkboxId;

            // Restore checked state
            if (checkedState[checkboxId]) {
                checkbox.checked = true;
            }

            // Save state on change
            checkbox.addEventListener('change', function() {
                checkedState[checkboxId] = this.checked;
                localStorage.setItem(storageKey, JSON.stringify(checkedState));
            });
        });
    </script>
</body>
</html>
